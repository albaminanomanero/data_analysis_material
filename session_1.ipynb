{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1:  Introduction to Data Analysis in R for Economics and Business\n",
    "### Data analysis for Economics and Management (Academic Course 2025-2026)\n",
    "\n",
    "Alba Mi√±ano-Ma√±ero (alba.minano@iseg.ulisboa.pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Welcome to our first programming class\n",
    "\n",
    "Today is our first session working with **R** as part of the course on data analysis for economics and business.\n",
    "\n",
    "###  Objectives for today's session\n",
    "\n",
    "In this first class, you will:\n",
    "1. Install **R** and **RStudio** \n",
    "2.  Open and explore a real-world **cross-sectional dataset** in **R**   \n",
    "3. Learn how to **save your work and outputs**  \n",
    "4. **R** basics: Prepare data for analysis, including handling **missing values**  \n",
    "5. Create and interpret **frequency tables**, **bar charts**, **histograms**, and **pie charts**  \n",
    "6.  Understand basic **data visualization and interpretation** using R  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Overview of setup and installation \n",
    "**What is **R**?**\n",
    "\n",
    "R is a domain-specific, high-level programming language (i.e., easy for humans to read and interpret) created in the early 1990s by statisticians *R*oss Ihaka and *R*obert Gentleman (any clue on where the name is comes from?). Designed specifically for statistical computing and data visualization, R serves as a robust environment for analyzing, modeling, and visualizing data‚Äîparticularly useful in academic, economic, and business contexts.\n",
    "\n",
    "R emphasizes data-centric thinking, making it natural to manipulate datasets, perform statistical operations, and generate publication-ready graphics. Though not a general-purpose language like Python, R excels in its intended domain, supporting procedural and functional paradigms with syntax tailored to statistical workflows.\n",
    "\n",
    "R‚Äôs power lies in its packages, including the popular Tidyverse, which streamline tasks like data cleaning, transformation, and plotting. It is widely used in research, public policy, economics, healthcare, and finance, and remains a top choice for data-intensive analysis and reproducible research.\n",
    "\n",
    "**Why **R**?**\n",
    "\n",
    "- R is purpose-built for data analysis, statistics, and visualization.\n",
    "- R is free, open-source, and supported by a strong academic and professional community.\n",
    "-  integrates easily with tools like Excel, SQL, and Python, and supports advanced analytics including machine learning and forecasting.\n",
    "\n",
    "**How R differs from other languages?**\n",
    "\n",
    "- Unlike Python or Java, R is not general-purpose‚Äîit‚Äôs designed specifically for statistical computing.\n",
    "- R‚Äôs syntax is optimized for data and model-oriented tasks, reducing the need for complex programming constructs.\n",
    "- R includes thousands of specialized packages (like the Tidyverse) that streamline analysis for non-programmers.\n",
    "\n",
    "\n",
    "However, R can feel less intuitive at first for beginners, and installation or package compatibility may require attention. By the end of this course, you‚Äôll have the minimal foundation needed to use R effectively in academic, business, or research settings.\n",
    "\n",
    "**Why moving from spreadsheets?**\n",
    "\n",
    "- Reproducibility: Code provides an explicit, version‚Äëcontrolled record of every step‚Äîunlike point‚Äëand‚Äëclick spreadsheets.  \n",
    "- Scale: Programming supports loops, functions, and scripts, making it easy to automate repetitive or complex tasks.  \n",
    "- Transparency & Debugging: Errors in code are easier to detect, test, and fix compared to hidden spreadsheet formulas.\n",
    "\n",
    "**Remote use on Binder** \n",
    "\n",
    "I have created a Binder environment that you can access online through your web browser. This platform allows you to run R sessions and work with all the course materials without needing to install anything on your own computer.\n",
    "\n",
    "While it may take a little time to load initially, Binder is the best option for us to share the exact same setup, ensuring everyone is working with the same software and files. This helps avoid compatibility issues and makes collaboration easier.\n",
    "\n",
    "Please note that Binder instances are ephemeral. This means you can experiment freely with the code and data during your session without affecting the original files. However, once you close the session, all your changes will be lost unless you download a local copy of your work. So, if you want to save your progress, be sure to export your files before ending the session.\n",
    "\n",
    "That said, it‚Äôs still a good idea to have R and RStudio installed locally on your desktop for more flexibility and faster performance when you‚Äôre working independently.\n",
    "\n",
    "You can access it [here](https://mybinder.org/v2/gh/albaminanomanero/data_analysis_iseg/HEAD) or in [https://mybinder.org/](https://mybinder.org/) by looking to putting in the search tab ''albaminanomanero/data_analysis_iseg''. All material of the course will be posted there and on the class Team. \n",
    "\n",
    "![Binder Start](https://raw.githubusercontent.com/albaminanomanero/data_analysis_iseg/refs/heads/main/imgs/binder_1.png)\n",
    "1. Menu Bar:\n",
    "   - File: options related to files and directories\n",
    "   - Edit: options related to editing documents\n",
    "   - View: options  that alter the appearance of JupyterLab\n",
    "   - Run: options for running code.\n",
    "   - Kernel: actions for managing kernels, which are separate processes for running code. \n",
    "   - Tabs: open documents and activities in the dock panel\n",
    "   - Settings: common settings and an advanced settings editor\n",
    "   - Help:  help links\n",
    "2. Shortcuts on File Browser.  \n",
    "3. Lef-side bar (Shortcuts to File browser/ Running Content / Github / Extensions)\n",
    "4. File Browser\n",
    "5. Right-side bar:\n",
    "   - Property Inspector: Displays metadata and settings for the currently selected notebook cell (e.g., tags, slide type).\n",
    "   - Kernel Usage: Shows CPU/RAM consumption and allows you to manage the active kernel (restart, shut down, etc.).\n",
    "   - Debugger: Offers breakpoints, call stack navigation, variable inspection, and step‚Äëthrough controls when debugging code.\n",
    "\n",
    "\n",
    "**Local installation via Conda**\n",
    "\n",
    "We can install R directly from the [Comprehensive R Archive Network (CRAN)](https://cran.r-project.org/). This installation equips us to write and run R code directly from the command line or R‚Äôs basic console. However, this approach can be quite unintuitive for beginners just starting with programming or data analysis.\n",
    "\n",
    "That‚Äôs where **I**ntegrated **D**evelopment **E**nvironments (IDEs) and editors come in. They provide a more user-friendly interface for writing, organizing, and running code. Features like syntax highlighting, code completion, debugging tools, and project management make programming more efficient and accessible at any skill level.\n",
    "\n",
    "While R has its own native IDE called RStudio, in this course **we will use [VSCode](https://code.visualstudio.com) rather than RStudio**, because VSCode is a very versatile editor that supports almost any open-source programming language with just a few clicks. This flexibility means you can continue using the same environment as you expand your programming skills beyond R.\n",
    "\n",
    "When you install R, you get a core set of functions, but much of R‚Äôs power comes from its packages‚Äîextensions developed by the community that add specialized functions, data types, and tools. For example, packages like **tidyverse** provide tools for data manipulation and visualization, while others support statistical modeling, machine learning, and more.\n",
    "\n",
    "However, managing packages and their dependencies can sometimes lead to conflicts or version issues. That's why to make sure everyone uses the local setup, we will follow an installation with Conda. \n",
    "\n",
    "To make sure we all work in the same environment, we will not install R directly. Instead, we‚Äôll use [Anaconda](https://www.anaconda.com/download), a Python and R distribution that includes the Conda package and environment manager. This allows us to install everything we need‚ÄîR itself, plus all required packages‚Äîin a controlled and reproducible way.\n",
    "\n",
    "1. **Install Anaconda**  \n",
    "   Download and install Anaconda from [here](https://www.anaconda.com/download).\n",
    "\n",
    "2. **Install VSCode**  \n",
    "   Download VSCode from [here](https://code.visualstudio.com). VSCode will serve as our IDE for both Python and R.\n",
    "\n",
    "3. **Download the Environment File**  \n",
    "   Download the `environment.yml` configuration:  \n",
    "   [https://github.com/albaminanomanero/data_analysis_iseg/blob/main/environment.yml](https://github.com/albaminanomanero/data_analysis_iseg/blob/main/environment.yml)\n",
    "\n",
    "   This file includes everything needed to recreate the same R environment.\n",
    "\n",
    "4. **Open terminal (Mac) or Anaconda Terminal (Windows)**\n",
    "\n",
    "   ---\n",
    "   ####  Windows\n",
    "   Use the **Anaconda Prompt** (not the regular Command Prompt):\n",
    "\n",
    "   1. Click on the **Start** menu.\n",
    "   2. Type `Anaconda Prompt` in the search bar.\n",
    "   3. Click to open it.\n",
    "\n",
    "   This will launch an Anaconda terminal with Conda already configured.\n",
    "\n",
    "   ---\n",
    "   ####  macOS\n",
    "   Use the built-in **Terminal** application:\n",
    "   1. Open **Finder**.\n",
    "   2. Go to **Applications > Utilities**.\n",
    "   3. Double-click on **Terminal**.\n",
    "\n",
    "   Alternatively, press `Cmd + Space` to open **Spotlight Search**, type `Terminal`, and hit `Enter`.\n",
    "\n",
    "\n",
    "5. **Change the directory to the folder where we have stored the downloaded file**\n",
    "   Type `cd path/to/environment`, where `path/to/environment` is the folder containing the environment configuration file in the terminal (i.e, Downloads folder)\n",
    "\n",
    "3. **Create environment**:\n",
    "   Type in the terminal: `conda env create -f environment.yml` \n",
    "\n",
    "4. **Check installation**:\n",
    "   Type in the terminal to activate the environment: `conda activate data_analysis_iseg`.\n",
    "\n",
    "> **Note**  \n",
    "> If you choose to install R using the base installation from [CRAN](https://cran.r-project.org), you‚Äôll need to manually install and load each required package on first use. For example:\n",
    "> ```r\n",
    "> install.packages(c(\n",
    ">   \"tidyverse\",    # data manipulation & visualization\n",
    ">   \"IRkernel\",     # R kernel for Jupyter\n",
    ">   \"essentials\",   # essential R packages\n",
    ">   \"readr\",        # data import tools\n",
    ">   \"readxl\"        # Excel import\n",
    "> ))\n",
    "\n",
    "### 2. R Notebooks with Jupyter\n",
    "\n",
    "In this course, we‚Äôll write and run **R** code interactively using **Jupyter Notebooks**‚Äîeither locally in VSCode or remotely via Binder. Both options give you the **exact same environment** and workflow:\n",
    "\n",
    "\n",
    "#### Why Jupyter Notebooks?\n",
    "\n",
    "Jupyter is an open‚Äësource project providing **computational notebooks** that combine:\n",
    "\n",
    "1. **Code cells** (here, R code via the IRkernel)  \n",
    "2. **Markdown cells** for narrative, equations, and images  \n",
    "3. **Outputs** (plots, tables, printed results)  \n",
    "\n",
    "Notebooks capture your entire analysis‚Äîcode, results, and explanations‚Äîin a single shareable `.ipynb` file (JSON under the hood), which you can version‚Äëcontrol, export to PDF/HTML, or open in any Jupyter‚Äëcompatible interface.\n",
    "\n",
    "#### Two Ways to Use Notebooks\n",
    "\n",
    "1. **VSCode**  \n",
    "   - Open VSCode  \n",
    "   - Install the R and Jupyter extensions (`R`, `R LSP Client`, `Jupyter`)  \n",
    "   - **File ‚Üí New File ‚Üí Jupyter Notebook**  \n",
    "   - Select the `data_analysis_iseg` Conda environment and the **R** kernel  \n",
    "\n",
    "2. **Binder**  \n",
    "   - Go to the Binder link provided  \n",
    "   - It launches the **same** `data_analysis_iseg` environment in your browser  \n",
    "   - No local installation required  \n",
    "\n",
    "> **Note:** Both VSCode and Binder use the **IRkernel** under the hood, so your notebooks behave identically.\n",
    "\n",
    "\n",
    "#### Notebook Anatomy\n",
    "\n",
    "- **Toolbar**  \n",
    "  Run cells, restart the kernel, save, etc.  \n",
    "- **Cell types**  \n",
    "  - **Code**: write R code (plots, data manipulation, models)  \n",
    "  - **Markdown**: document your workflow with text, lists, equations  \n",
    "  - **Raw**: uninterpreted content for export  \n",
    "\n",
    "- **Execution**  \n",
    "  - Press **Shift‚ÄØ+‚ÄØEnter** or click ‚ñ∂Ô∏è to run a cell.  \n",
    "  - All cells share the same R kernel‚Äîvariables and functions persist until you restart.\n",
    "\n",
    "---\n",
    "\n",
    "#### Quick Tips\n",
    "\n",
    "- **Interrupt** a long‚Äërunning cell with the stop ‚èπÔ∏è button.  \n",
    "- **Restart Kernel** to clear all variables and start fresh.  \n",
    "- **Export** your notebook via **File ‚Üí Export** to share PDF/HTML versions.\n",
    "\n",
    "---\n",
    "\n",
    "Whether in VSCode or on Binder, Jupyter Notebooks give you a **reproducible, interactive** workspace for all your R analyses. Let‚Äôs open a new notebook and get started!  \n",
    "\n",
    "![Notebooks on Binder](https://raw.githubusercontent.com/albaminanomanero/data_analysis_iseg/refs/heads/main/imgs/notebook_1.png)\n",
    "1. Name of our new notebook: notice that when a white point appears is because there are unsaved changes. Notice that notebooks have the **.ipynb** extension. \n",
    "2. Menu bar: Save, add new cell, cut, copy, paste, run cell, stop running, restart kernel, restart and run all, download, browser saving options, upload, folder with course documents, Binder link, \n",
    "3. Type of cell (Code, Markdown, Raw)\n",
    "4. Open Notebook on separate side. \n",
    "5. Kernel running (you can select R/Python etc)\n",
    "6. Kernel status \n",
    "7. Cell to write code; right icons allow to create more cells, move up and down the code and delete. \n",
    "\n",
    "After running a cell, either by pressing the `run' icon in 2 or shift enter, if the cell prints output it will show below it. \n",
    "\n",
    "![Notebooks on Binder 2](https://raw.githubusercontent.com/albaminanomanero/data_analysis_iseg/refs/heads/main/imgs/notebook_22.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Workflow for data analysis\n",
    "\n",
    "Use these steps as a blueprint for organizing your code and guiding your data analysis process:\n",
    "\n",
    "1. Load / Import Data (Today)\n",
    "2. Explore & Validate \n",
    "   - Summary statistics  \n",
    "   - Check for missing values  (Today)\n",
    "3. Clean & Transform\n",
    "   - Tidy data, filter, recode  \n",
    "   - Merge or reshape as needed  \n",
    "4. Analyze\n",
    "   - Descriptive tables & plots  \n",
    "   - From our theory classes!\n",
    "5. Model\n",
    "   - From our theory classes!\n",
    "6. Generate Outputs\n",
    "   - Tables \n",
    "   - Figures  \n",
    "   - Then, we can prepare our reports & presentations and extract conclusions from the analysis we have done. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we‚Äôve already covered a lot of programming concepts and theory in depth, we‚Äôll conclude today‚Äôs session with a few simple, hands‚Äëon examples‚Äîloading a dataset, generating frequency tables, and creating basic summaries‚Äîto see how these techniques come together in practice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Loading, simple cleaning and exporting data\n",
    "\n",
    "Because in the course we are either:\n",
    "\n",
    "- Using **Binder** to run our notebooks online, or  \n",
    "- Running R locally through a **conda environment** that already has the necessary packages installed.\n",
    "\n",
    "**We do *not* need to install anything manually.**\n",
    "\n",
    "> ‚ö†Ô∏è If you were running R on a fresh installation outside Binder or conda, you would first need to install the `readxl` package using:\n",
    "> ```r\n",
    "> install.packages(\"readxl\")\n",
    "> ```\n",
    "> Notice that you need the quotation marks (i.e., \" \") for the installation to work, otherwise it will give an error of object not found. \n",
    "\n",
    "> üí° Maybe you're starting to notice how useful it is to have a pre-configured environment like **conda** or **Binder**‚Äîyou can jump straight into the analysis without worrying about installation errors or package conflicts. \n",
    "\n",
    "#### Step 1: Loading the necessary packages. \n",
    "In this example, we just need to read an excel file so the only package we have to load is ```\"readxl\"```: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(readxl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntaxis to load packages is always the same: ```library(name of the package)```. While  we can also use the string to load the library (i.e., ```library(\"readxl\")```), the convention is to leave the strings for the installation of the package and load it without. When you work with packages in R, there are **two steps**:\n",
    "\n",
    "1. Installing a Package\n",
    "- This means **downloading and saving** the package on your computer.\n",
    "- You tell R the **name of the package as text** (a string), so R knows exactly what to download.\n",
    "2. Loading the pacakge: \n",
    "- After installing, you tell R to use the package in your current session.\n",
    "- Here, R already knows about the package because it‚Äôs installed (it's like a variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Set the Working Directory (Tell R Where Your File Is)\n",
    "\n",
    "To load a file, R needs to know **where it is stored** on your computer. This location is called the **path** ‚Äî basically the folder or directory where your file lives.\n",
    "\n",
    "Think of the **path** as the folder where the file is saved. If R doesn‚Äôt know this path, it won‚Äôt be able to find and load your Excel file. **It is NOT just the file name** (like `my_data.xlsx`), but includes the folders leading to it (like `C:/Users/YourName/Documents/my_data.xlsx`).\n",
    "\n",
    "\n",
    "When you work in R, you can:\n",
    "\n",
    "- **Use the current working directory**, if your files are all neatly organized there.  \n",
    "  This is easy because R will look for files in that folder by default ‚Äî no extra work needed.\n",
    "\n",
    "- Or, if your files are **somewhere else**, you need to tell R the exact path by setting the working directory.  \n",
    "  This is like saying:  \n",
    "  *‚ÄúHey R, go look for files in THIS specific folder.‚Äù*\n",
    "\n",
    "\n",
    "**How to Set the Working Directory if you are using VSCode**\n",
    "\n",
    "Use the `setwd()` function and give it the folder path as a string-- have you realized that ```setwd()``` reads as ***Set*** ***W***orking ***D***irectory?\n",
    "```r\n",
    "setwd(\"path/to/your/directory\")\n",
    "```\n",
    "Depending on your operating system: \n",
    "  - Windows:\n",
    "    ``` r \n",
    "    setwd(\"C:/Users/YourName/Documents\")\n",
    "    ```\n",
    "  - Mac: \n",
    "    ```r \n",
    "    setwd(\"~/Documents/\")\n",
    "    ```\n",
    "    \n",
    "To get the path: \n",
    "  - Windows:\n",
    "    1. Open the **folder** where your file is saved (for example, Documents).  \n",
    "    2. Click on the **address bar** at the top ‚Äî this shows the path.  \n",
    "    3. Copy that path (e.g., `C:\\Users\\YourName\\Documents`)\n",
    "    4. Paste on the code inside the ```setwd()```, do not forget to write it within \" \". \n",
    "  - Mac:\n",
    "    1. Right-click (or Control-click) the file or folder.\n",
    "    2. Press and hold the Option (‚å•) key ‚Äî the menu changes.\n",
    "    3. Click on \"Copy [folder] as Pathname\"\n",
    "    4. Paste on the code inside the ```setwd()```, do not forget to write it within \" \". \n",
    "\n",
    "\n",
    "Another useful function is ```getcwd()``` which tell use where the current working directory is located-- have you realized that ```getwd()``` reads as ***Get*** ***W***orking  ***D***irectory?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  What Happens with File Paths When You're Using Binder?\n",
    "\n",
    "When you're running on **Binder**, you're not working on your own computer. Instead, you're using a **temporary environment in the cloud**, created from a repository where I have stored the class material. This means the files Binder can \"see\" are only the ones that were included in the **project folder or repository** you uploaded or linked to Binder. That is, **you can't access files on your personal computer** (e.g., `C:/Users/...`) from Binder.\n",
    "\n",
    "In Binder, we always use **relative paths** ‚Äî paths that describe how to find a file **starting from the current folder**, not from the full location on your computer.\n",
    "\n",
    "For example:\n",
    "``` r\n",
    "read_excel(\"data/my_file.xlsx\")\n",
    "```\n",
    "\n",
    "This example is telling R: starting from the folder where this notebook is located, go into the data folder and open the file named my_file.xlsx.\n",
    "\n",
    "One of the great advantages of using relative paths is that as long as the folder structure is the same for two people, the code will just work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Load the data \n",
    "\n",
    "Now that your environment is set up and R knows where to find your file, it‚Äôs time to import your Excel data into your notebook.\n",
    "\n",
    "We‚Äôll use the `read_excel()` function from the `readxl` package. The basic syntax is:\n",
    "\n",
    "```r\n",
    "data <- read_excel(\"your_file.xlsx\")\n",
    "```\n",
    "where:\n",
    "- \"your_file.xlsx\" is the name of your file ‚Äî make sure it is spelled exactly as it appears, including the .xlsx extension.\n",
    "\n",
    "- data is the name of the variable where your dataset will be stored (you can name it whatever you like). \n",
    "\n",
    "> ‚ö†Ô∏è **Attention:**  \n",
    "> If the file is open in Excel on Windows, you might get this error:\n",
    ">\n",
    "> ```\n",
    "> Error in utils::unzip(zip_path, list = TRUE) :  \n",
    ">   zip file 'C:\\path\\your_file.xlsx' cannot be opened\n",
    "> ```\n",
    "> Go to excel and close it and you should be able to get it running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data <- read_excel(\"data/session_1/example_excel.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 100 √ó 8</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>0</th><th scope=col>First Name</th><th scope=col>Last Name</th><th scope=col>Gender</th><th scope=col>Country</th><th scope=col>Age</th><th scope=col>Date</th><th scope=col>Id</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1</td><td>Dulce    </td><td>Abril    </td><td>Female</td><td>United States</td><td>32</td><td>15/10/2017</td><td>1562</td></tr>\n",
       "\t<tr><td> 2</td><td>Mara     </td><td>Hashimoto</td><td>Female</td><td>Great Britain</td><td>25</td><td>16/08/2016</td><td>1582</td></tr>\n",
       "\t<tr><td> 3</td><td>Philip   </td><td>Gent     </td><td>Male  </td><td>France       </td><td>36</td><td>21/05/2015</td><td>2587</td></tr>\n",
       "\t<tr><td> 4</td><td>Kathleen </td><td>Hanner   </td><td>Female</td><td>United States</td><td>25</td><td>15/10/2017</td><td>3549</td></tr>\n",
       "\t<tr><td> 5</td><td>Nereida  </td><td>Magwood  </td><td>Female</td><td>United States</td><td>58</td><td>16/08/2016</td><td>2468</td></tr>\n",
       "\t<tr><td> 6</td><td>Gaston   </td><td>Brumm    </td><td>Male  </td><td>United States</td><td>24</td><td>21/05/2015</td><td>2554</td></tr>\n",
       "\t<tr><td> 7</td><td>Etta     </td><td>Hurn     </td><td>Female</td><td>Great Britain</td><td>56</td><td>15/10/2017</td><td>3598</td></tr>\n",
       "\t<tr><td> 8</td><td>Earlean  </td><td>Melgar   </td><td>Female</td><td>United States</td><td>27</td><td>16/08/2016</td><td>2456</td></tr>\n",
       "\t<tr><td> 9</td><td>Vincenza </td><td>Weiland  </td><td>Female</td><td>United States</td><td>40</td><td>21/05/2015</td><td>6548</td></tr>\n",
       "\t<tr><td>10</td><td>Fallon   </td><td>Winward  </td><td>Female</td><td>Great Britain</td><td>28</td><td>16/08/2016</td><td>5486</td></tr>\n",
       "\t<tr><td>11</td><td>Arcelia  </td><td>Bouska   </td><td>Female</td><td>Great Britain</td><td>39</td><td>21/05/2015</td><td>1258</td></tr>\n",
       "\t<tr><td>12</td><td>Franklyn </td><td>Unknow   </td><td>Male  </td><td>France       </td><td>38</td><td>15/10/2017</td><td>2579</td></tr>\n",
       "\t<tr><td>13</td><td>Sherron  </td><td>Ascencio </td><td>Female</td><td>Great Britain</td><td>32</td><td>16/08/2016</td><td>3256</td></tr>\n",
       "\t<tr><td>14</td><td>Marcel   </td><td>Zabriskie</td><td>Male  </td><td>Great Britain</td><td>26</td><td>21/05/2015</td><td>2587</td></tr>\n",
       "\t<tr><td>15</td><td>Kina     </td><td>Hazelton </td><td>Female</td><td>Great Britain</td><td>31</td><td>16/08/2016</td><td>3259</td></tr>\n",
       "\t<tr><td>16</td><td>Shavonne </td><td>Pia      </td><td>Female</td><td>France       </td><td>24</td><td>21/05/2015</td><td>1546</td></tr>\n",
       "\t<tr><td>17</td><td>Shavon   </td><td>Benito   </td><td>Female</td><td>France       </td><td>39</td><td>15/10/2017</td><td>3579</td></tr>\n",
       "\t<tr><td>18</td><td>Lauralee </td><td>Perrine  </td><td>Female</td><td>Great Britain</td><td>28</td><td>16/08/2016</td><td>6597</td></tr>\n",
       "\t<tr><td>19</td><td>Loreta   </td><td>Curren   </td><td>Female</td><td>France       </td><td>26</td><td>21/05/2015</td><td>9654</td></tr>\n",
       "\t<tr><td>20</td><td>Teresa   </td><td>Strawn   </td><td>Female</td><td>France       </td><td>46</td><td>21/05/2015</td><td>3569</td></tr>\n",
       "\t<tr><td>21</td><td>Belinda  </td><td>Partain  </td><td>Female</td><td>United States</td><td>37</td><td>15/10/2017</td><td>2564</td></tr>\n",
       "\t<tr><td>22</td><td>Holly    </td><td>Eudy     </td><td>Female</td><td>United States</td><td>52</td><td>16/08/2016</td><td>8561</td></tr>\n",
       "\t<tr><td>23</td><td>Many     </td><td>Cuccia   </td><td>Female</td><td>Great Britain</td><td>46</td><td>21/05/2015</td><td>5489</td></tr>\n",
       "\t<tr><td>24</td><td>Libbie   </td><td>Dalby    </td><td>Female</td><td>France       </td><td>42</td><td>21/05/2015</td><td>5489</td></tr>\n",
       "\t<tr><td>25</td><td>Lester   </td><td>Prothro  </td><td>Male  </td><td>France       </td><td>21</td><td>15/10/2017</td><td>6574</td></tr>\n",
       "\t<tr><td>26</td><td>Marvel   </td><td>Hail     </td><td>Female</td><td>Great Britain</td><td>28</td><td>16/08/2016</td><td>5555</td></tr>\n",
       "\t<tr><td>27</td><td>Angelyn  </td><td>Vong     </td><td>Female</td><td>United States</td><td>29</td><td>21/05/2015</td><td>6125</td></tr>\n",
       "\t<tr><td>28</td><td>Francesca</td><td>Beaudreau</td><td>Female</td><td>France       </td><td>23</td><td>15/10/2017</td><td>5412</td></tr>\n",
       "\t<tr><td>29</td><td>Garth    </td><td>Gangi    </td><td>Male  </td><td>United States</td><td>41</td><td>16/08/2016</td><td>3256</td></tr>\n",
       "\t<tr><td>30</td><td>Carla    </td><td>Trumbull </td><td>Female</td><td>Great Britain</td><td>28</td><td>21/05/2015</td><td>3264</td></tr>\n",
       "\t<tr><td>‚ãÆ</td><td>‚ãÆ</td><td>‚ãÆ</td><td>‚ãÆ</td><td>‚ãÆ</td><td>‚ãÆ</td><td>‚ãÆ</td><td>‚ãÆ</td></tr>\n",
       "\t<tr><td> 71</td><td>Belinda  </td><td>Partain   </td><td>Female</td><td>United States</td><td>37</td><td>15/10/2017</td><td>2564</td></tr>\n",
       "\t<tr><td> 72</td><td>Holly    </td><td>Eudy      </td><td>Female</td><td>United States</td><td>52</td><td>16/08/2016</td><td>8561</td></tr>\n",
       "\t<tr><td> 73</td><td>Many     </td><td>Cuccia    </td><td>Female</td><td>Great Britain</td><td>46</td><td>21/05/2015</td><td>5489</td></tr>\n",
       "\t<tr><td> 74</td><td>Libbie   </td><td>Dalby     </td><td>Female</td><td>France       </td><td>42</td><td>21/05/2015</td><td>5489</td></tr>\n",
       "\t<tr><td> 75</td><td>Lester   </td><td>Prothro   </td><td>Male  </td><td>France       </td><td>21</td><td>15/10/2017</td><td>6574</td></tr>\n",
       "\t<tr><td> 76</td><td>Marvel   </td><td>Hail      </td><td>Female</td><td>Great Britain</td><td>28</td><td>16/08/2016</td><td>5555</td></tr>\n",
       "\t<tr><td> 77</td><td>Angelyn  </td><td>Vong      </td><td>Female</td><td>United States</td><td>29</td><td>21/05/2015</td><td>6125</td></tr>\n",
       "\t<tr><td> 78</td><td>Francesca</td><td>Beaudreau </td><td>Female</td><td>France       </td><td>23</td><td>15/10/2017</td><td>5412</td></tr>\n",
       "\t<tr><td> 79</td><td>Garth    </td><td>Gangi     </td><td>Male  </td><td>United States</td><td>41</td><td>16/08/2016</td><td>3256</td></tr>\n",
       "\t<tr><td> 80</td><td>Carla    </td><td>Trumbull  </td><td>Female</td><td>Great Britain</td><td>28</td><td>21/05/2015</td><td>3264</td></tr>\n",
       "\t<tr><td> 81</td><td>Veta     </td><td>Muntz     </td><td>Female</td><td>Great Britain</td><td>37</td><td>15/10/2017</td><td>4569</td></tr>\n",
       "\t<tr><td> 82</td><td>Stasia   </td><td>Becker    </td><td>Female</td><td>Great Britain</td><td>34</td><td>16/08/2016</td><td>7521</td></tr>\n",
       "\t<tr><td> 83</td><td>Jona     </td><td>Grindle   </td><td>Female</td><td>Great Britain</td><td>26</td><td>21/05/2015</td><td>6458</td></tr>\n",
       "\t<tr><td> 84</td><td>Judie    </td><td>Claywell  </td><td>Female</td><td>France       </td><td>35</td><td>16/08/2016</td><td>7569</td></tr>\n",
       "\t<tr><td> 85</td><td>Dewitt   </td><td>Borger    </td><td>Male  </td><td>United States</td><td>36</td><td>21/05/2015</td><td>8514</td></tr>\n",
       "\t<tr><td> 86</td><td>Nena     </td><td>Hacker    </td><td>Female</td><td>United States</td><td>29</td><td>15/10/2017</td><td>8563</td></tr>\n",
       "\t<tr><td> 87</td><td>Kelsie   </td><td>Wachtel   </td><td>Female</td><td>France       </td><td>27</td><td>16/08/2016</td><td>8642</td></tr>\n",
       "\t<tr><td> 88</td><td>Sau      </td><td>Pfau      </td><td>Female</td><td>United States</td><td>25</td><td>21/05/2015</td><td>9536</td></tr>\n",
       "\t<tr><td> 89</td><td>Shanice  </td><td>Mccrystal </td><td>Female</td><td>United States</td><td>36</td><td>21/05/2015</td><td>2567</td></tr>\n",
       "\t<tr><td> 90</td><td>Chase    </td><td>Karner    </td><td>Male  </td><td>United States</td><td>37</td><td>15/10/2017</td><td>2154</td></tr>\n",
       "\t<tr><td> 91</td><td>Tommie   </td><td>Underdahl </td><td>Male  </td><td>United States</td><td>26</td><td>16/08/2016</td><td>3265</td></tr>\n",
       "\t<tr><td> 92</td><td>Dorcas   </td><td>Darity    </td><td>Female</td><td>United States</td><td>37</td><td>21/05/2015</td><td>8765</td></tr>\n",
       "\t<tr><td> 93</td><td>Angel    </td><td>Sanor     </td><td>Male  </td><td>France       </td><td>24</td><td>15/10/2017</td><td>3259</td></tr>\n",
       "\t<tr><td> 94</td><td>Willodean</td><td>Harn      </td><td>Female</td><td>United States</td><td>39</td><td>16/08/2016</td><td>3567</td></tr>\n",
       "\t<tr><td> 95</td><td>Weston   </td><td>Martina   </td><td>Male  </td><td>United States</td><td>26</td><td>21/05/2015</td><td>6540</td></tr>\n",
       "\t<tr><td> 96</td><td>Roma     </td><td>Lafollette</td><td>Female</td><td>United States</td><td>34</td><td>15/10/2017</td><td>2654</td></tr>\n",
       "\t<tr><td> 97</td><td>Felisa   </td><td>Cail      </td><td>Female</td><td>United States</td><td>28</td><td>16/08/2016</td><td>6525</td></tr>\n",
       "\t<tr><td> 98</td><td>Demetria </td><td>Abbey     </td><td>Female</td><td>United States</td><td>32</td><td>21/05/2015</td><td>3265</td></tr>\n",
       "\t<tr><td> 99</td><td>Jeromy   </td><td>Danz      </td><td>Male  </td><td>United States</td><td>39</td><td>15/10/2017</td><td>3265</td></tr>\n",
       "\t<tr><td>100</td><td>Rasheeda </td><td>Alkire    </td><td>Female</td><td>United States</td><td>29</td><td>16/08/2016</td><td>6125</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 100 √ó 8\n",
       "\\begin{tabular}{llllllll}\n",
       " 0 & First Name & Last Name & Gender & Country & Age & Date & Id\\\\\n",
       " <dbl> & <chr> & <chr> & <chr> & <chr> & <dbl> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t  1 & Dulce     & Abril     & Female & United States & 32 & 15/10/2017 & 1562\\\\\n",
       "\t  2 & Mara      & Hashimoto & Female & Great Britain & 25 & 16/08/2016 & 1582\\\\\n",
       "\t  3 & Philip    & Gent      & Male   & France        & 36 & 21/05/2015 & 2587\\\\\n",
       "\t  4 & Kathleen  & Hanner    & Female & United States & 25 & 15/10/2017 & 3549\\\\\n",
       "\t  5 & Nereida   & Magwood   & Female & United States & 58 & 16/08/2016 & 2468\\\\\n",
       "\t  6 & Gaston    & Brumm     & Male   & United States & 24 & 21/05/2015 & 2554\\\\\n",
       "\t  7 & Etta      & Hurn      & Female & Great Britain & 56 & 15/10/2017 & 3598\\\\\n",
       "\t  8 & Earlean   & Melgar    & Female & United States & 27 & 16/08/2016 & 2456\\\\\n",
       "\t  9 & Vincenza  & Weiland   & Female & United States & 40 & 21/05/2015 & 6548\\\\\n",
       "\t 10 & Fallon    & Winward   & Female & Great Britain & 28 & 16/08/2016 & 5486\\\\\n",
       "\t 11 & Arcelia   & Bouska    & Female & Great Britain & 39 & 21/05/2015 & 1258\\\\\n",
       "\t 12 & Franklyn  & Unknow    & Male   & France        & 38 & 15/10/2017 & 2579\\\\\n",
       "\t 13 & Sherron   & Ascencio  & Female & Great Britain & 32 & 16/08/2016 & 3256\\\\\n",
       "\t 14 & Marcel    & Zabriskie & Male   & Great Britain & 26 & 21/05/2015 & 2587\\\\\n",
       "\t 15 & Kina      & Hazelton  & Female & Great Britain & 31 & 16/08/2016 & 3259\\\\\n",
       "\t 16 & Shavonne  & Pia       & Female & France        & 24 & 21/05/2015 & 1546\\\\\n",
       "\t 17 & Shavon    & Benito    & Female & France        & 39 & 15/10/2017 & 3579\\\\\n",
       "\t 18 & Lauralee  & Perrine   & Female & Great Britain & 28 & 16/08/2016 & 6597\\\\\n",
       "\t 19 & Loreta    & Curren    & Female & France        & 26 & 21/05/2015 & 9654\\\\\n",
       "\t 20 & Teresa    & Strawn    & Female & France        & 46 & 21/05/2015 & 3569\\\\\n",
       "\t 21 & Belinda   & Partain   & Female & United States & 37 & 15/10/2017 & 2564\\\\\n",
       "\t 22 & Holly     & Eudy      & Female & United States & 52 & 16/08/2016 & 8561\\\\\n",
       "\t 23 & Many      & Cuccia    & Female & Great Britain & 46 & 21/05/2015 & 5489\\\\\n",
       "\t 24 & Libbie    & Dalby     & Female & France        & 42 & 21/05/2015 & 5489\\\\\n",
       "\t 25 & Lester    & Prothro   & Male   & France        & 21 & 15/10/2017 & 6574\\\\\n",
       "\t 26 & Marvel    & Hail      & Female & Great Britain & 28 & 16/08/2016 & 5555\\\\\n",
       "\t 27 & Angelyn   & Vong      & Female & United States & 29 & 21/05/2015 & 6125\\\\\n",
       "\t 28 & Francesca & Beaudreau & Female & France        & 23 & 15/10/2017 & 5412\\\\\n",
       "\t 29 & Garth     & Gangi     & Male   & United States & 41 & 16/08/2016 & 3256\\\\\n",
       "\t 30 & Carla     & Trumbull  & Female & Great Britain & 28 & 21/05/2015 & 3264\\\\\n",
       "\t ‚ãÆ & ‚ãÆ & ‚ãÆ & ‚ãÆ & ‚ãÆ & ‚ãÆ & ‚ãÆ & ‚ãÆ\\\\\n",
       "\t  71 & Belinda   & Partain    & Female & United States & 37 & 15/10/2017 & 2564\\\\\n",
       "\t  72 & Holly     & Eudy       & Female & United States & 52 & 16/08/2016 & 8561\\\\\n",
       "\t  73 & Many      & Cuccia     & Female & Great Britain & 46 & 21/05/2015 & 5489\\\\\n",
       "\t  74 & Libbie    & Dalby      & Female & France        & 42 & 21/05/2015 & 5489\\\\\n",
       "\t  75 & Lester    & Prothro    & Male   & France        & 21 & 15/10/2017 & 6574\\\\\n",
       "\t  76 & Marvel    & Hail       & Female & Great Britain & 28 & 16/08/2016 & 5555\\\\\n",
       "\t  77 & Angelyn   & Vong       & Female & United States & 29 & 21/05/2015 & 6125\\\\\n",
       "\t  78 & Francesca & Beaudreau  & Female & France        & 23 & 15/10/2017 & 5412\\\\\n",
       "\t  79 & Garth     & Gangi      & Male   & United States & 41 & 16/08/2016 & 3256\\\\\n",
       "\t  80 & Carla     & Trumbull   & Female & Great Britain & 28 & 21/05/2015 & 3264\\\\\n",
       "\t  81 & Veta      & Muntz      & Female & Great Britain & 37 & 15/10/2017 & 4569\\\\\n",
       "\t  82 & Stasia    & Becker     & Female & Great Britain & 34 & 16/08/2016 & 7521\\\\\n",
       "\t  83 & Jona      & Grindle    & Female & Great Britain & 26 & 21/05/2015 & 6458\\\\\n",
       "\t  84 & Judie     & Claywell   & Female & France        & 35 & 16/08/2016 & 7569\\\\\n",
       "\t  85 & Dewitt    & Borger     & Male   & United States & 36 & 21/05/2015 & 8514\\\\\n",
       "\t  86 & Nena      & Hacker     & Female & United States & 29 & 15/10/2017 & 8563\\\\\n",
       "\t  87 & Kelsie    & Wachtel    & Female & France        & 27 & 16/08/2016 & 8642\\\\\n",
       "\t  88 & Sau       & Pfau       & Female & United States & 25 & 21/05/2015 & 9536\\\\\n",
       "\t  89 & Shanice   & Mccrystal  & Female & United States & 36 & 21/05/2015 & 2567\\\\\n",
       "\t  90 & Chase     & Karner     & Male   & United States & 37 & 15/10/2017 & 2154\\\\\n",
       "\t  91 & Tommie    & Underdahl  & Male   & United States & 26 & 16/08/2016 & 3265\\\\\n",
       "\t  92 & Dorcas    & Darity     & Female & United States & 37 & 21/05/2015 & 8765\\\\\n",
       "\t  93 & Angel     & Sanor      & Male   & France        & 24 & 15/10/2017 & 3259\\\\\n",
       "\t  94 & Willodean & Harn       & Female & United States & 39 & 16/08/2016 & 3567\\\\\n",
       "\t  95 & Weston    & Martina    & Male   & United States & 26 & 21/05/2015 & 6540\\\\\n",
       "\t  96 & Roma      & Lafollette & Female & United States & 34 & 15/10/2017 & 2654\\\\\n",
       "\t  97 & Felisa    & Cail       & Female & United States & 28 & 16/08/2016 & 6525\\\\\n",
       "\t  98 & Demetria  & Abbey      & Female & United States & 32 & 21/05/2015 & 3265\\\\\n",
       "\t  99 & Jeromy    & Danz       & Male   & United States & 39 & 15/10/2017 & 3265\\\\\n",
       "\t 100 & Rasheeda  & Alkire     & Female & United States & 29 & 16/08/2016 & 6125\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 100 √ó 8\n",
       "\n",
       "| 0 &lt;dbl&gt; | First Name &lt;chr&gt; | Last Name &lt;chr&gt; | Gender &lt;chr&gt; | Country &lt;chr&gt; | Age &lt;dbl&gt; | Date &lt;chr&gt; | Id &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "|  1 | Dulce     | Abril     | Female | United States | 32 | 15/10/2017 | 1562 |\n",
       "|  2 | Mara      | Hashimoto | Female | Great Britain | 25 | 16/08/2016 | 1582 |\n",
       "|  3 | Philip    | Gent      | Male   | France        | 36 | 21/05/2015 | 2587 |\n",
       "|  4 | Kathleen  | Hanner    | Female | United States | 25 | 15/10/2017 | 3549 |\n",
       "|  5 | Nereida   | Magwood   | Female | United States | 58 | 16/08/2016 | 2468 |\n",
       "|  6 | Gaston    | Brumm     | Male   | United States | 24 | 21/05/2015 | 2554 |\n",
       "|  7 | Etta      | Hurn      | Female | Great Britain | 56 | 15/10/2017 | 3598 |\n",
       "|  8 | Earlean   | Melgar    | Female | United States | 27 | 16/08/2016 | 2456 |\n",
       "|  9 | Vincenza  | Weiland   | Female | United States | 40 | 21/05/2015 | 6548 |\n",
       "| 10 | Fallon    | Winward   | Female | Great Britain | 28 | 16/08/2016 | 5486 |\n",
       "| 11 | Arcelia   | Bouska    | Female | Great Britain | 39 | 21/05/2015 | 1258 |\n",
       "| 12 | Franklyn  | Unknow    | Male   | France        | 38 | 15/10/2017 | 2579 |\n",
       "| 13 | Sherron   | Ascencio  | Female | Great Britain | 32 | 16/08/2016 | 3256 |\n",
       "| 14 | Marcel    | Zabriskie | Male   | Great Britain | 26 | 21/05/2015 | 2587 |\n",
       "| 15 | Kina      | Hazelton  | Female | Great Britain | 31 | 16/08/2016 | 3259 |\n",
       "| 16 | Shavonne  | Pia       | Female | France        | 24 | 21/05/2015 | 1546 |\n",
       "| 17 | Shavon    | Benito    | Female | France        | 39 | 15/10/2017 | 3579 |\n",
       "| 18 | Lauralee  | Perrine   | Female | Great Britain | 28 | 16/08/2016 | 6597 |\n",
       "| 19 | Loreta    | Curren    | Female | France        | 26 | 21/05/2015 | 9654 |\n",
       "| 20 | Teresa    | Strawn    | Female | France        | 46 | 21/05/2015 | 3569 |\n",
       "| 21 | Belinda   | Partain   | Female | United States | 37 | 15/10/2017 | 2564 |\n",
       "| 22 | Holly     | Eudy      | Female | United States | 52 | 16/08/2016 | 8561 |\n",
       "| 23 | Many      | Cuccia    | Female | Great Britain | 46 | 21/05/2015 | 5489 |\n",
       "| 24 | Libbie    | Dalby     | Female | France        | 42 | 21/05/2015 | 5489 |\n",
       "| 25 | Lester    | Prothro   | Male   | France        | 21 | 15/10/2017 | 6574 |\n",
       "| 26 | Marvel    | Hail      | Female | Great Britain | 28 | 16/08/2016 | 5555 |\n",
       "| 27 | Angelyn   | Vong      | Female | United States | 29 | 21/05/2015 | 6125 |\n",
       "| 28 | Francesca | Beaudreau | Female | France        | 23 | 15/10/2017 | 5412 |\n",
       "| 29 | Garth     | Gangi     | Male   | United States | 41 | 16/08/2016 | 3256 |\n",
       "| 30 | Carla     | Trumbull  | Female | Great Britain | 28 | 21/05/2015 | 3264 |\n",
       "| ‚ãÆ | ‚ãÆ | ‚ãÆ | ‚ãÆ | ‚ãÆ | ‚ãÆ | ‚ãÆ | ‚ãÆ |\n",
       "|  71 | Belinda   | Partain    | Female | United States | 37 | 15/10/2017 | 2564 |\n",
       "|  72 | Holly     | Eudy       | Female | United States | 52 | 16/08/2016 | 8561 |\n",
       "|  73 | Many      | Cuccia     | Female | Great Britain | 46 | 21/05/2015 | 5489 |\n",
       "|  74 | Libbie    | Dalby      | Female | France        | 42 | 21/05/2015 | 5489 |\n",
       "|  75 | Lester    | Prothro    | Male   | France        | 21 | 15/10/2017 | 6574 |\n",
       "|  76 | Marvel    | Hail       | Female | Great Britain | 28 | 16/08/2016 | 5555 |\n",
       "|  77 | Angelyn   | Vong       | Female | United States | 29 | 21/05/2015 | 6125 |\n",
       "|  78 | Francesca | Beaudreau  | Female | France        | 23 | 15/10/2017 | 5412 |\n",
       "|  79 | Garth     | Gangi      | Male   | United States | 41 | 16/08/2016 | 3256 |\n",
       "|  80 | Carla     | Trumbull   | Female | Great Britain | 28 | 21/05/2015 | 3264 |\n",
       "|  81 | Veta      | Muntz      | Female | Great Britain | 37 | 15/10/2017 | 4569 |\n",
       "|  82 | Stasia    | Becker     | Female | Great Britain | 34 | 16/08/2016 | 7521 |\n",
       "|  83 | Jona      | Grindle    | Female | Great Britain | 26 | 21/05/2015 | 6458 |\n",
       "|  84 | Judie     | Claywell   | Female | France        | 35 | 16/08/2016 | 7569 |\n",
       "|  85 | Dewitt    | Borger     | Male   | United States | 36 | 21/05/2015 | 8514 |\n",
       "|  86 | Nena      | Hacker     | Female | United States | 29 | 15/10/2017 | 8563 |\n",
       "|  87 | Kelsie    | Wachtel    | Female | France        | 27 | 16/08/2016 | 8642 |\n",
       "|  88 | Sau       | Pfau       | Female | United States | 25 | 21/05/2015 | 9536 |\n",
       "|  89 | Shanice   | Mccrystal  | Female | United States | 36 | 21/05/2015 | 2567 |\n",
       "|  90 | Chase     | Karner     | Male   | United States | 37 | 15/10/2017 | 2154 |\n",
       "|  91 | Tommie    | Underdahl  | Male   | United States | 26 | 16/08/2016 | 3265 |\n",
       "|  92 | Dorcas    | Darity     | Female | United States | 37 | 21/05/2015 | 8765 |\n",
       "|  93 | Angel     | Sanor      | Male   | France        | 24 | 15/10/2017 | 3259 |\n",
       "|  94 | Willodean | Harn       | Female | United States | 39 | 16/08/2016 | 3567 |\n",
       "|  95 | Weston    | Martina    | Male   | United States | 26 | 21/05/2015 | 6540 |\n",
       "|  96 | Roma      | Lafollette | Female | United States | 34 | 15/10/2017 | 2654 |\n",
       "|  97 | Felisa    | Cail       | Female | United States | 28 | 16/08/2016 | 6525 |\n",
       "|  98 | Demetria  | Abbey      | Female | United States | 32 | 21/05/2015 | 3265 |\n",
       "|  99 | Jeromy    | Danz       | Male   | United States | 39 | 15/10/2017 | 3265 |\n",
       "| 100 | Rasheeda  | Alkire     | Female | United States | 29 | 16/08/2016 | 6125 |\n",
       "\n"
      ],
      "text/plain": [
       "    0   First Name Last Name  Gender Country       Age Date       Id  \n",
       "1    1  Dulce      Abril      Female United States 32  15/10/2017 1562\n",
       "2    2  Mara       Hashimoto  Female Great Britain 25  16/08/2016 1582\n",
       "3    3  Philip     Gent       Male   France        36  21/05/2015 2587\n",
       "4    4  Kathleen   Hanner     Female United States 25  15/10/2017 3549\n",
       "5    5  Nereida    Magwood    Female United States 58  16/08/2016 2468\n",
       "6    6  Gaston     Brumm      Male   United States 24  21/05/2015 2554\n",
       "7    7  Etta       Hurn       Female Great Britain 56  15/10/2017 3598\n",
       "8    8  Earlean    Melgar     Female United States 27  16/08/2016 2456\n",
       "9    9  Vincenza   Weiland    Female United States 40  21/05/2015 6548\n",
       "10  10  Fallon     Winward    Female Great Britain 28  16/08/2016 5486\n",
       "11  11  Arcelia    Bouska     Female Great Britain 39  21/05/2015 1258\n",
       "12  12  Franklyn   Unknow     Male   France        38  15/10/2017 2579\n",
       "13  13  Sherron    Ascencio   Female Great Britain 32  16/08/2016 3256\n",
       "14  14  Marcel     Zabriskie  Male   Great Britain 26  21/05/2015 2587\n",
       "15  15  Kina       Hazelton   Female Great Britain 31  16/08/2016 3259\n",
       "16  16  Shavonne   Pia        Female France        24  21/05/2015 1546\n",
       "17  17  Shavon     Benito     Female France        39  15/10/2017 3579\n",
       "18  18  Lauralee   Perrine    Female Great Britain 28  16/08/2016 6597\n",
       "19  19  Loreta     Curren     Female France        26  21/05/2015 9654\n",
       "20  20  Teresa     Strawn     Female France        46  21/05/2015 3569\n",
       "21  21  Belinda    Partain    Female United States 37  15/10/2017 2564\n",
       "22  22  Holly      Eudy       Female United States 52  16/08/2016 8561\n",
       "23  23  Many       Cuccia     Female Great Britain 46  21/05/2015 5489\n",
       "24  24  Libbie     Dalby      Female France        42  21/05/2015 5489\n",
       "25  25  Lester     Prothro    Male   France        21  15/10/2017 6574\n",
       "26  26  Marvel     Hail       Female Great Britain 28  16/08/2016 5555\n",
       "27  27  Angelyn    Vong       Female United States 29  21/05/2015 6125\n",
       "28  28  Francesca  Beaudreau  Female France        23  15/10/2017 5412\n",
       "29  29  Garth      Gangi      Male   United States 41  16/08/2016 3256\n",
       "30  30  Carla      Trumbull   Female Great Britain 28  21/05/2015 3264\n",
       "‚ãÆ   ‚ãÆ   ‚ãÆ          ‚ãÆ          ‚ãÆ      ‚ãÆ             ‚ãÆ   ‚ãÆ          ‚ãÆ   \n",
       "71   71 Belinda    Partain    Female United States 37  15/10/2017 2564\n",
       "72   72 Holly      Eudy       Female United States 52  16/08/2016 8561\n",
       "73   73 Many       Cuccia     Female Great Britain 46  21/05/2015 5489\n",
       "74   74 Libbie     Dalby      Female France        42  21/05/2015 5489\n",
       "75   75 Lester     Prothro    Male   France        21  15/10/2017 6574\n",
       "76   76 Marvel     Hail       Female Great Britain 28  16/08/2016 5555\n",
       "77   77 Angelyn    Vong       Female United States 29  21/05/2015 6125\n",
       "78   78 Francesca  Beaudreau  Female France        23  15/10/2017 5412\n",
       "79   79 Garth      Gangi      Male   United States 41  16/08/2016 3256\n",
       "80   80 Carla      Trumbull   Female Great Britain 28  21/05/2015 3264\n",
       "81   81 Veta       Muntz      Female Great Britain 37  15/10/2017 4569\n",
       "82   82 Stasia     Becker     Female Great Britain 34  16/08/2016 7521\n",
       "83   83 Jona       Grindle    Female Great Britain 26  21/05/2015 6458\n",
       "84   84 Judie      Claywell   Female France        35  16/08/2016 7569\n",
       "85   85 Dewitt     Borger     Male   United States 36  21/05/2015 8514\n",
       "86   86 Nena       Hacker     Female United States 29  15/10/2017 8563\n",
       "87   87 Kelsie     Wachtel    Female France        27  16/08/2016 8642\n",
       "88   88 Sau        Pfau       Female United States 25  21/05/2015 9536\n",
       "89   89 Shanice    Mccrystal  Female United States 36  21/05/2015 2567\n",
       "90   90 Chase      Karner     Male   United States 37  15/10/2017 2154\n",
       "91   91 Tommie     Underdahl  Male   United States 26  16/08/2016 3265\n",
       "92   92 Dorcas     Darity     Female United States 37  21/05/2015 8765\n",
       "93   93 Angel      Sanor      Male   France        24  15/10/2017 3259\n",
       "94   94 Willodean  Harn       Female United States 39  16/08/2016 3567\n",
       "95   95 Weston     Martina    Male   United States 26  21/05/2015 6540\n",
       "96   96 Roma       Lafollette Female United States 34  15/10/2017 2654\n",
       "97   97 Felisa     Cail       Female United States 28  16/08/2016 6525\n",
       "98   98 Demetria   Abbey      Female United States 32  21/05/2015 3265\n",
       "99   99 Jeromy     Danz       Male   United States 39  15/10/2017 3265\n",
       "100 100 Rasheeda   Alkire     Female United States 29  16/08/2016 6125"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your Excel file contains multiple sheets (tabs), you can read a specific one using the `sheet = argument`:\n",
    "\n",
    "```r\n",
    "data <- read_excel(\"your_file.xlsx\", sheet = \"sheet_name\")\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data <- read_excel(\"data/session_1/example_excel.xls\", sheet = \"first_30\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ‚ö†Ô∏è **Notice:** When you create a variable with the same name as an existing one in R, you are overwriting the original variable. This means the previous value stored in that variable will be replaced by the new value. Be careful when naming variables to avoid unintentionally losing important data. In this example, ``data`` has been replaced by the code above that was loading the sheet ''first_30'' rather than the first sheet. \n",
    "\n",
    "A few interesting funcitons to know about:\n",
    "- `head()`, which shows just the first few rows of the data, making it easier to get a quick glimpse without printing everything. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 √ó 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>0</th><th scope=col>First Name</th><th scope=col>Last Name</th><th scope=col>Gender</th><th scope=col>Country</th><th scope=col>Age</th><th scope=col>Id</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>Dulce   </td><td>Abril    </td><td>Female</td><td>United States</td><td>32</td><td>1562</td></tr>\n",
       "\t<tr><td>2</td><td>Mara    </td><td>Hashimoto</td><td>Female</td><td>Great Britain</td><td>25</td><td>  NA</td></tr>\n",
       "\t<tr><td>3</td><td>Philip  </td><td>Gent     </td><td>Male  </td><td>France       </td><td>36</td><td>2587</td></tr>\n",
       "\t<tr><td>4</td><td>Kathleen</td><td>Hanner   </td><td>Female</td><td>United States</td><td>25</td><td>  NA</td></tr>\n",
       "\t<tr><td>5</td><td>Nereida </td><td>Magwood  </td><td>Female</td><td>United States</td><td>58</td><td>2468</td></tr>\n",
       "\t<tr><td>6</td><td>Gaston  </td><td>Brumm    </td><td>Male  </td><td>United States</td><td>24</td><td>2554</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 √ó 7\n",
       "\\begin{tabular}{lllllll}\n",
       " 0 & First Name & Last Name & Gender & Country & Age & Id\\\\\n",
       " <dbl> & <chr> & <chr> & <chr> & <chr> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 1 & Dulce    & Abril     & Female & United States & 32 & 1562\\\\\n",
       "\t 2 & Mara     & Hashimoto & Female & Great Britain & 25 &   NA\\\\\n",
       "\t 3 & Philip   & Gent      & Male   & France        & 36 & 2587\\\\\n",
       "\t 4 & Kathleen & Hanner    & Female & United States & 25 &   NA\\\\\n",
       "\t 5 & Nereida  & Magwood   & Female & United States & 58 & 2468\\\\\n",
       "\t 6 & Gaston   & Brumm     & Male   & United States & 24 & 2554\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 √ó 7\n",
       "\n",
       "| 0 &lt;dbl&gt; | First Name &lt;chr&gt; | Last Name &lt;chr&gt; | Gender &lt;chr&gt; | Country &lt;chr&gt; | Age &lt;dbl&gt; | Id &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 1 | Dulce    | Abril     | Female | United States | 32 | 1562 |\n",
       "| 2 | Mara     | Hashimoto | Female | Great Britain | 25 |   NA |\n",
       "| 3 | Philip   | Gent      | Male   | France        | 36 | 2587 |\n",
       "| 4 | Kathleen | Hanner    | Female | United States | 25 |   NA |\n",
       "| 5 | Nereida  | Magwood   | Female | United States | 58 | 2468 |\n",
       "| 6 | Gaston   | Brumm     | Male   | United States | 24 | 2554 |\n",
       "\n"
      ],
      "text/plain": [
       "  0 First Name Last Name Gender Country       Age Id  \n",
       "1 1 Dulce      Abril     Female United States 32  1562\n",
       "2 2 Mara       Hashimoto Female Great Britain 25    NA\n",
       "3 3 Philip     Gent      Male   France        36  2587\n",
       "4 4 Kathleen   Hanner    Female United States 25    NA\n",
       "5 5 Nereida    Magwood   Female United States 58  2468\n",
       "6 6 Gaston     Brumm     Male   United States 24  2554"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify the amount of rows you want to show by passing it as an argument. For instance ``head(data,10)`` will show the first 10 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 10 √ó 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>0</th><th scope=col>First Name</th><th scope=col>Last Name</th><th scope=col>Gender</th><th scope=col>Country</th><th scope=col>Age</th><th scope=col>Id</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1</td><td>Dulce   </td><td>Abril    </td><td>Female</td><td>United States</td><td>32</td><td>1562</td></tr>\n",
       "\t<tr><td> 2</td><td>Mara    </td><td>Hashimoto</td><td>Female</td><td>Great Britain</td><td>25</td><td>  NA</td></tr>\n",
       "\t<tr><td> 3</td><td>Philip  </td><td>Gent     </td><td>Male  </td><td>France       </td><td>36</td><td>2587</td></tr>\n",
       "\t<tr><td> 4</td><td>Kathleen</td><td>Hanner   </td><td>Female</td><td>United States</td><td>25</td><td>  NA</td></tr>\n",
       "\t<tr><td> 5</td><td>Nereida </td><td>Magwood  </td><td>Female</td><td>United States</td><td>58</td><td>2468</td></tr>\n",
       "\t<tr><td> 6</td><td>Gaston  </td><td>Brumm    </td><td>Male  </td><td>United States</td><td>24</td><td>2554</td></tr>\n",
       "\t<tr><td> 7</td><td>Etta    </td><td>Hurn     </td><td>Female</td><td>Great Britain</td><td>56</td><td>  NA</td></tr>\n",
       "\t<tr><td> 8</td><td>Earlean </td><td>Melgar   </td><td>Female</td><td>United States</td><td>27</td><td>2456</td></tr>\n",
       "\t<tr><td> 9</td><td>Vincenza</td><td>Weiland  </td><td>Female</td><td>United States</td><td>40</td><td>6548</td></tr>\n",
       "\t<tr><td>10</td><td>Fallon  </td><td>Winward  </td><td>Female</td><td>Great Britain</td><td>28</td><td>  NA</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 10 √ó 7\n",
       "\\begin{tabular}{lllllll}\n",
       " 0 & First Name & Last Name & Gender & Country & Age & Id\\\\\n",
       " <dbl> & <chr> & <chr> & <chr> & <chr> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t  1 & Dulce    & Abril     & Female & United States & 32 & 1562\\\\\n",
       "\t  2 & Mara     & Hashimoto & Female & Great Britain & 25 &   NA\\\\\n",
       "\t  3 & Philip   & Gent      & Male   & France        & 36 & 2587\\\\\n",
       "\t  4 & Kathleen & Hanner    & Female & United States & 25 &   NA\\\\\n",
       "\t  5 & Nereida  & Magwood   & Female & United States & 58 & 2468\\\\\n",
       "\t  6 & Gaston   & Brumm     & Male   & United States & 24 & 2554\\\\\n",
       "\t  7 & Etta     & Hurn      & Female & Great Britain & 56 &   NA\\\\\n",
       "\t  8 & Earlean  & Melgar    & Female & United States & 27 & 2456\\\\\n",
       "\t  9 & Vincenza & Weiland   & Female & United States & 40 & 6548\\\\\n",
       "\t 10 & Fallon   & Winward   & Female & Great Britain & 28 &   NA\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 10 √ó 7\n",
       "\n",
       "| 0 &lt;dbl&gt; | First Name &lt;chr&gt; | Last Name &lt;chr&gt; | Gender &lt;chr&gt; | Country &lt;chr&gt; | Age &lt;dbl&gt; | Id &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "|  1 | Dulce    | Abril     | Female | United States | 32 | 1562 |\n",
       "|  2 | Mara     | Hashimoto | Female | Great Britain | 25 |   NA |\n",
       "|  3 | Philip   | Gent      | Male   | France        | 36 | 2587 |\n",
       "|  4 | Kathleen | Hanner    | Female | United States | 25 |   NA |\n",
       "|  5 | Nereida  | Magwood   | Female | United States | 58 | 2468 |\n",
       "|  6 | Gaston   | Brumm     | Male   | United States | 24 | 2554 |\n",
       "|  7 | Etta     | Hurn      | Female | Great Britain | 56 |   NA |\n",
       "|  8 | Earlean  | Melgar    | Female | United States | 27 | 2456 |\n",
       "|  9 | Vincenza | Weiland   | Female | United States | 40 | 6548 |\n",
       "| 10 | Fallon   | Winward   | Female | Great Britain | 28 |   NA |\n",
       "\n"
      ],
      "text/plain": [
       "   0  First Name Last Name Gender Country       Age Id  \n",
       "1   1 Dulce      Abril     Female United States 32  1562\n",
       "2   2 Mara       Hashimoto Female Great Britain 25    NA\n",
       "3   3 Philip     Gent      Male   France        36  2587\n",
       "4   4 Kathleen   Hanner    Female United States 25    NA\n",
       "5   5 Nereida    Magwood   Female United States 58  2468\n",
       "6   6 Gaston     Brumm     Male   United States 24  2554\n",
       "7   7 Etta       Hurn      Female Great Britain 56    NA\n",
       "8   8 Earlean    Melgar    Female United States 27  2456\n",
       "9   9 Vincenza   Weiland   Female United States 40  6548\n",
       "10 10 Fallon     Winward   Female Great Britain 28    NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that below the variable name we get the type of variable (more on this on the next session). In this case, our variables are:\n",
    "- **dbl** ‚Äî double (a numeric type with decimal points)\n",
    "\n",
    "- **chr** ‚Äî character (text/string data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `summary()`, which provides key statistics like minimum, maximum, median, mean, and quartiles for each variable for all the columns in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       0          First Name         Last Name            Gender         \n",
       " Min.   : 1.00   Length:30          Length:30          Length:30         \n",
       " 1st Qu.: 8.25   Class :character   Class :character   Class :character  \n",
       " Median :15.50   Mode  :character   Mode  :character   Mode  :character  \n",
       " Mean   :15.50                                                           \n",
       " 3rd Qu.:22.75                                                           \n",
       " Max.   :30.00                                                           \n",
       "                                                                         \n",
       "   Country               Age              Id      \n",
       " Length:30          Min.   :21.00   Min.   :1258  \n",
       " Class :character   1st Qu.:26.25   1st Qu.:2562  \n",
       " Mode  :character   Median :31.50   Median :3262  \n",
       "                    Mean   :34.23   Mean   :4132  \n",
       "                    3rd Qu.:39.75   3rd Qu.:5506  \n",
       "                    Max.   :58.00   Max.   :9654  \n",
       "                                    NA's   :6     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to describe just one column, you can use ```data$column_name``` as argument for describe. In fact, for all R syntaxis we will always call a column as ```data_name$column_name```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "‚ÄúUnknown or uninitialised column: `age`.‚Äù\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Length  Class   Mode \n",
       "     0   NULL   NULL "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(data$age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "What just happened? We tried to access the column `age`, but R returned `NULL` for all values. This means that no column named `age` exists in the dataset. But wait‚Äîdidn't we see a column that looked like `age`? The key point is that **R is case sensitive**. This means `age`, `Age`, `AGe`, etc...  are all considered different names. In this case, our actual column was named `Age` with a capital ‚ÄúA,‚Äù so calling `data$age` didn‚Äôt work. To fix this, always use the exact capitalization of the column name when accessing it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "  21.00   26.25   31.50   34.23   39.75   58.00 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(data$Age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Handling missing values\n",
    "\n",
    "Missing values, often represented as `NA` in R, indicate that data is not available or wasn‚Äôt recorded for a particular observation. They can occur for many reasons ‚Äî data entry errors, sensor failures, or respondents skipping questions, for example.\n",
    "\n",
    "**Why Do We Need to Check for Missing Values?**\n",
    "- Functions might return errors or incorrect results.\n",
    "\n",
    "- Statistical summaries can be biased.\n",
    "\n",
    "- Models might fail to train or give unreliable predictions.\n",
    "\n",
    "To identify missing values, we can  use the funciton `is.na()`, which will print a ''mask'' of the data. This means that the values of the observations will be `FALSE` (if there is valid data in that row) or `TRUE` if that observation has missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 30 √ó 7 of type lgl</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>0</th><th scope=col>First Name</th><th scope=col>Last Name</th><th scope=col>Gender</th><th scope=col>Country</th><th scope=col>Age</th><th scope=col>Id</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td> TRUE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 30 √ó 7 of type lgl\n",
       "\\begin{tabular}{lllllll}\n",
       " 0 & First Name & Last Name & Gender & Country & Age & Id\\\\\n",
       "\\hline\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE &  TRUE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 30 √ó 7 of type lgl\n",
       "\n",
       "| 0 | First Name | Last Name | Gender | Country | Age | Id |\n",
       "|---|---|---|---|---|---|---|\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |  TRUE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "\n"
      ],
      "text/plain": [
       "      0     First Name Last Name Gender Country Age   Id   \n",
       " [1,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       " [2,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE  TRUE\n",
       " [3,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       " [4,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE  TRUE\n",
       " [5,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       " [6,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       " [7,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE  TRUE\n",
       " [8,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       " [9,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       "[10,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE  TRUE\n",
       "[11,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       "[12,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       "[13,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       "[14,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE  TRUE\n",
       "[15,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       "[16,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       "[17,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       "[18,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE  TRUE\n",
       "[19,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       "[20,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       "[21,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       "[22,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       "[23,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       "[24,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       "[25,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       "[26,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       "[27,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       "[28,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       "[29,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE\n",
       "[30,] FALSE FALSE      FALSE     FALSE  FALSE   FALSE FALSE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "is.na(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `is.na()` returns a logical matrix of `TRUE` and `FALSE` values, it can be hard to interpret directly for large data frames. Instead, we can sum across rows or columns to quickly count how many missing values there are. This works because R automatically converts`FALSE` to 0 and `TRUE` to 1 when performing arithmetic operations. So, summing these logical values gives the total number of missing entries in each row or column.\n",
    "\n",
    "Summing within column we see that only the column `ID` has 4 missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>0</dt><dd>0</dd><dt>First Name</dt><dd>0</dd><dt>Last Name</dt><dd>0</dd><dt>Gender</dt><dd>0</dd><dt>Country</dt><dd>0</dd><dt>Age</dt><dd>0</dd><dt>Id</dt><dd>6</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[0] 0\n",
       "\\item[First Name] 0\n",
       "\\item[Last Name] 0\n",
       "\\item[Gender] 0\n",
       "\\item[Country] 0\n",
       "\\item[Age] 0\n",
       "\\item[Id] 6\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "0\n",
       ":   0First Name\n",
       ":   0Last Name\n",
       ":   0Gender\n",
       ":   0Country\n",
       ":   0Age\n",
       ":   0Id\n",
       ":   6\n",
       "\n"
      ],
      "text/plain": [
       "         0 First Name  Last Name     Gender    Country        Age         Id \n",
       "         0          0          0          0          0          0          6 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colSums(is.na(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `colSums(is.na(data))` is passing the output of `is.na(data)` as input to colSums(). \n",
    "Alternatively, you could first store the result in a variable, like `missing_mask <- is.na(data)`, and then call colSums(missing_mask). Both ways give the same result. \n",
    "\n",
    "If we sum for rows we will obtain a vector where each element corresponds to a row in the dataset. A value of 0 means that row has no missing values, while a value greater than 0 indicates how many missing values are present in that row. So, rows with any missing data will have a number ‚â• 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0</li><li>1</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0\n",
       "2. 1\n",
       "3. 0\n",
       "4. 1\n",
       "5. 0\n",
       "6. 0\n",
       "7. 1\n",
       "8. 0\n",
       "9. 0\n",
       "10. 1\n",
       "11. 0\n",
       "12. 0\n",
       "13. 0\n",
       "14. 1\n",
       "15. 0\n",
       "16. 0\n",
       "17. 0\n",
       "18. 1\n",
       "19. 0\n",
       "20. 0\n",
       "21. 0\n",
       "22. 0\n",
       "23. 0\n",
       "24. 0\n",
       "25. 0\n",
       "26. 0\n",
       "27. 0\n",
       "28. 0\n",
       "29. 0\n",
       "30. 0\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rowSums(is.na(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can proceed in different ways to remove the missing values:\n",
    "\n",
    "1. Remove any row with `NA` values:\n",
    "\n",
    "    (Notice that the second row, which had a missing value dissapears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 24 √ó 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>0</th><th scope=col>First Name</th><th scope=col>Last Name</th><th scope=col>Gender</th><th scope=col>Country</th><th scope=col>Age</th><th scope=col>Id</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1</td><td>Dulce    </td><td>Abril    </td><td>Female</td><td>United States</td><td>32</td><td>1562</td></tr>\n",
       "\t<tr><td> 3</td><td>Philip   </td><td>Gent     </td><td>Male  </td><td>France       </td><td>36</td><td>2587</td></tr>\n",
       "\t<tr><td> 5</td><td>Nereida  </td><td>Magwood  </td><td>Female</td><td>United States</td><td>58</td><td>2468</td></tr>\n",
       "\t<tr><td> 6</td><td>Gaston   </td><td>Brumm    </td><td>Male  </td><td>United States</td><td>24</td><td>2554</td></tr>\n",
       "\t<tr><td> 8</td><td>Earlean  </td><td>Melgar   </td><td>Female</td><td>United States</td><td>27</td><td>2456</td></tr>\n",
       "\t<tr><td> 9</td><td>Vincenza </td><td>Weiland  </td><td>Female</td><td>United States</td><td>40</td><td>6548</td></tr>\n",
       "\t<tr><td>11</td><td>Arcelia  </td><td>Bouska   </td><td>Female</td><td>Great Britain</td><td>39</td><td>1258</td></tr>\n",
       "\t<tr><td>12</td><td>Franklyn </td><td>Unknow   </td><td>Male  </td><td>France       </td><td>38</td><td>2579</td></tr>\n",
       "\t<tr><td>13</td><td>Sherron  </td><td>Ascencio </td><td>Female</td><td>Great Britain</td><td>32</td><td>3256</td></tr>\n",
       "\t<tr><td>15</td><td>Kina     </td><td>Hazelton </td><td>Female</td><td>Great Britain</td><td>31</td><td>3259</td></tr>\n",
       "\t<tr><td>16</td><td>Shavonne </td><td>Pia      </td><td>Female</td><td>France       </td><td>24</td><td>1546</td></tr>\n",
       "\t<tr><td>17</td><td>Shavon   </td><td>Benito   </td><td>Female</td><td>France       </td><td>39</td><td>3579</td></tr>\n",
       "\t<tr><td>19</td><td>Loreta   </td><td>Curren   </td><td>Female</td><td>France       </td><td>26</td><td>9654</td></tr>\n",
       "\t<tr><td>20</td><td>Teresa   </td><td>Strawn   </td><td>Female</td><td>France       </td><td>46</td><td>3569</td></tr>\n",
       "\t<tr><td>21</td><td>Belinda  </td><td>Partain  </td><td>Female</td><td>United States</td><td>37</td><td>2564</td></tr>\n",
       "\t<tr><td>22</td><td>Holly    </td><td>Eudy     </td><td>Female</td><td>United States</td><td>52</td><td>8561</td></tr>\n",
       "\t<tr><td>23</td><td>Many     </td><td>Cuccia   </td><td>Female</td><td>Great Britain</td><td>46</td><td>5489</td></tr>\n",
       "\t<tr><td>24</td><td>Libbie   </td><td>Dalby    </td><td>Female</td><td>France       </td><td>42</td><td>5489</td></tr>\n",
       "\t<tr><td>25</td><td>Lester   </td><td>Prothro  </td><td>Male  </td><td>France       </td><td>21</td><td>6574</td></tr>\n",
       "\t<tr><td>26</td><td>Marvel   </td><td>Hail     </td><td>Female</td><td>Great Britain</td><td>28</td><td>5555</td></tr>\n",
       "\t<tr><td>27</td><td>Angelyn  </td><td>Vong     </td><td>Female</td><td>United States</td><td>29</td><td>6125</td></tr>\n",
       "\t<tr><td>28</td><td>Francesca</td><td>Beaudreau</td><td>Female</td><td>France       </td><td>23</td><td>5412</td></tr>\n",
       "\t<tr><td>29</td><td>Garth    </td><td>Gangi    </td><td>Male  </td><td>United States</td><td>41</td><td>3256</td></tr>\n",
       "\t<tr><td>30</td><td>Carla    </td><td>Trumbull </td><td>Female</td><td>Great Britain</td><td>28</td><td>3264</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 24 √ó 7\n",
       "\\begin{tabular}{lllllll}\n",
       " 0 & First Name & Last Name & Gender & Country & Age & Id\\\\\n",
       " <dbl> & <chr> & <chr> & <chr> & <chr> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t  1 & Dulce     & Abril     & Female & United States & 32 & 1562\\\\\n",
       "\t  3 & Philip    & Gent      & Male   & France        & 36 & 2587\\\\\n",
       "\t  5 & Nereida   & Magwood   & Female & United States & 58 & 2468\\\\\n",
       "\t  6 & Gaston    & Brumm     & Male   & United States & 24 & 2554\\\\\n",
       "\t  8 & Earlean   & Melgar    & Female & United States & 27 & 2456\\\\\n",
       "\t  9 & Vincenza  & Weiland   & Female & United States & 40 & 6548\\\\\n",
       "\t 11 & Arcelia   & Bouska    & Female & Great Britain & 39 & 1258\\\\\n",
       "\t 12 & Franklyn  & Unknow    & Male   & France        & 38 & 2579\\\\\n",
       "\t 13 & Sherron   & Ascencio  & Female & Great Britain & 32 & 3256\\\\\n",
       "\t 15 & Kina      & Hazelton  & Female & Great Britain & 31 & 3259\\\\\n",
       "\t 16 & Shavonne  & Pia       & Female & France        & 24 & 1546\\\\\n",
       "\t 17 & Shavon    & Benito    & Female & France        & 39 & 3579\\\\\n",
       "\t 19 & Loreta    & Curren    & Female & France        & 26 & 9654\\\\\n",
       "\t 20 & Teresa    & Strawn    & Female & France        & 46 & 3569\\\\\n",
       "\t 21 & Belinda   & Partain   & Female & United States & 37 & 2564\\\\\n",
       "\t 22 & Holly     & Eudy      & Female & United States & 52 & 8561\\\\\n",
       "\t 23 & Many      & Cuccia    & Female & Great Britain & 46 & 5489\\\\\n",
       "\t 24 & Libbie    & Dalby     & Female & France        & 42 & 5489\\\\\n",
       "\t 25 & Lester    & Prothro   & Male   & France        & 21 & 6574\\\\\n",
       "\t 26 & Marvel    & Hail      & Female & Great Britain & 28 & 5555\\\\\n",
       "\t 27 & Angelyn   & Vong      & Female & United States & 29 & 6125\\\\\n",
       "\t 28 & Francesca & Beaudreau & Female & France        & 23 & 5412\\\\\n",
       "\t 29 & Garth     & Gangi     & Male   & United States & 41 & 3256\\\\\n",
       "\t 30 & Carla     & Trumbull  & Female & Great Britain & 28 & 3264\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 24 √ó 7\n",
       "\n",
       "| 0 &lt;dbl&gt; | First Name &lt;chr&gt; | Last Name &lt;chr&gt; | Gender &lt;chr&gt; | Country &lt;chr&gt; | Age &lt;dbl&gt; | Id &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "|  1 | Dulce     | Abril     | Female | United States | 32 | 1562 |\n",
       "|  3 | Philip    | Gent      | Male   | France        | 36 | 2587 |\n",
       "|  5 | Nereida   | Magwood   | Female | United States | 58 | 2468 |\n",
       "|  6 | Gaston    | Brumm     | Male   | United States | 24 | 2554 |\n",
       "|  8 | Earlean   | Melgar    | Female | United States | 27 | 2456 |\n",
       "|  9 | Vincenza  | Weiland   | Female | United States | 40 | 6548 |\n",
       "| 11 | Arcelia   | Bouska    | Female | Great Britain | 39 | 1258 |\n",
       "| 12 | Franklyn  | Unknow    | Male   | France        | 38 | 2579 |\n",
       "| 13 | Sherron   | Ascencio  | Female | Great Britain | 32 | 3256 |\n",
       "| 15 | Kina      | Hazelton  | Female | Great Britain | 31 | 3259 |\n",
       "| 16 | Shavonne  | Pia       | Female | France        | 24 | 1546 |\n",
       "| 17 | Shavon    | Benito    | Female | France        | 39 | 3579 |\n",
       "| 19 | Loreta    | Curren    | Female | France        | 26 | 9654 |\n",
       "| 20 | Teresa    | Strawn    | Female | France        | 46 | 3569 |\n",
       "| 21 | Belinda   | Partain   | Female | United States | 37 | 2564 |\n",
       "| 22 | Holly     | Eudy      | Female | United States | 52 | 8561 |\n",
       "| 23 | Many      | Cuccia    | Female | Great Britain | 46 | 5489 |\n",
       "| 24 | Libbie    | Dalby     | Female | France        | 42 | 5489 |\n",
       "| 25 | Lester    | Prothro   | Male   | France        | 21 | 6574 |\n",
       "| 26 | Marvel    | Hail      | Female | Great Britain | 28 | 5555 |\n",
       "| 27 | Angelyn   | Vong      | Female | United States | 29 | 6125 |\n",
       "| 28 | Francesca | Beaudreau | Female | France        | 23 | 5412 |\n",
       "| 29 | Garth     | Gangi     | Male   | United States | 41 | 3256 |\n",
       "| 30 | Carla     | Trumbull  | Female | Great Britain | 28 | 3264 |\n",
       "\n"
      ],
      "text/plain": [
       "   0  First Name Last Name Gender Country       Age Id  \n",
       "1   1 Dulce      Abril     Female United States 32  1562\n",
       "2   3 Philip     Gent      Male   France        36  2587\n",
       "3   5 Nereida    Magwood   Female United States 58  2468\n",
       "4   6 Gaston     Brumm     Male   United States 24  2554\n",
       "5   8 Earlean    Melgar    Female United States 27  2456\n",
       "6   9 Vincenza   Weiland   Female United States 40  6548\n",
       "7  11 Arcelia    Bouska    Female Great Britain 39  1258\n",
       "8  12 Franklyn   Unknow    Male   France        38  2579\n",
       "9  13 Sherron    Ascencio  Female Great Britain 32  3256\n",
       "10 15 Kina       Hazelton  Female Great Britain 31  3259\n",
       "11 16 Shavonne   Pia       Female France        24  1546\n",
       "12 17 Shavon     Benito    Female France        39  3579\n",
       "13 19 Loreta     Curren    Female France        26  9654\n",
       "14 20 Teresa     Strawn    Female France        46  3569\n",
       "15 21 Belinda    Partain   Female United States 37  2564\n",
       "16 22 Holly      Eudy      Female United States 52  8561\n",
       "17 23 Many       Cuccia    Female Great Britain 46  5489\n",
       "18 24 Libbie     Dalby     Female France        42  5489\n",
       "19 25 Lester     Prothro   Male   France        21  6574\n",
       "20 26 Marvel     Hail      Female Great Britain 28  5555\n",
       "21 27 Angelyn    Vong      Female United States 29  6125\n",
       "22 28 Francesca  Beaudreau Female France        23  5412\n",
       "23 29 Garth      Gangi     Male   United States 41  3256\n",
       "24 30 Carla      Trumbull  Female Great Britain 28  3264"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "na.omit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. If we have multiple columns with missing values, we can remove rows with missing values in a specifi column as: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 24 √ó 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>0</th><th scope=col>First Name</th><th scope=col>Last Name</th><th scope=col>Gender</th><th scope=col>Country</th><th scope=col>Age</th><th scope=col>Id</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1</td><td>Dulce    </td><td>Abril    </td><td>Female</td><td>United States</td><td>32</td><td>1562</td></tr>\n",
       "\t<tr><td> 3</td><td>Philip   </td><td>Gent     </td><td>Male  </td><td>France       </td><td>36</td><td>2587</td></tr>\n",
       "\t<tr><td> 5</td><td>Nereida  </td><td>Magwood  </td><td>Female</td><td>United States</td><td>58</td><td>2468</td></tr>\n",
       "\t<tr><td> 6</td><td>Gaston   </td><td>Brumm    </td><td>Male  </td><td>United States</td><td>24</td><td>2554</td></tr>\n",
       "\t<tr><td> 8</td><td>Earlean  </td><td>Melgar   </td><td>Female</td><td>United States</td><td>27</td><td>2456</td></tr>\n",
       "\t<tr><td> 9</td><td>Vincenza </td><td>Weiland  </td><td>Female</td><td>United States</td><td>40</td><td>6548</td></tr>\n",
       "\t<tr><td>11</td><td>Arcelia  </td><td>Bouska   </td><td>Female</td><td>Great Britain</td><td>39</td><td>1258</td></tr>\n",
       "\t<tr><td>12</td><td>Franklyn </td><td>Unknow   </td><td>Male  </td><td>France       </td><td>38</td><td>2579</td></tr>\n",
       "\t<tr><td>13</td><td>Sherron  </td><td>Ascencio </td><td>Female</td><td>Great Britain</td><td>32</td><td>3256</td></tr>\n",
       "\t<tr><td>15</td><td>Kina     </td><td>Hazelton </td><td>Female</td><td>Great Britain</td><td>31</td><td>3259</td></tr>\n",
       "\t<tr><td>16</td><td>Shavonne </td><td>Pia      </td><td>Female</td><td>France       </td><td>24</td><td>1546</td></tr>\n",
       "\t<tr><td>17</td><td>Shavon   </td><td>Benito   </td><td>Female</td><td>France       </td><td>39</td><td>3579</td></tr>\n",
       "\t<tr><td>19</td><td>Loreta   </td><td>Curren   </td><td>Female</td><td>France       </td><td>26</td><td>9654</td></tr>\n",
       "\t<tr><td>20</td><td>Teresa   </td><td>Strawn   </td><td>Female</td><td>France       </td><td>46</td><td>3569</td></tr>\n",
       "\t<tr><td>21</td><td>Belinda  </td><td>Partain  </td><td>Female</td><td>United States</td><td>37</td><td>2564</td></tr>\n",
       "\t<tr><td>22</td><td>Holly    </td><td>Eudy     </td><td>Female</td><td>United States</td><td>52</td><td>8561</td></tr>\n",
       "\t<tr><td>23</td><td>Many     </td><td>Cuccia   </td><td>Female</td><td>Great Britain</td><td>46</td><td>5489</td></tr>\n",
       "\t<tr><td>24</td><td>Libbie   </td><td>Dalby    </td><td>Female</td><td>France       </td><td>42</td><td>5489</td></tr>\n",
       "\t<tr><td>25</td><td>Lester   </td><td>Prothro  </td><td>Male  </td><td>France       </td><td>21</td><td>6574</td></tr>\n",
       "\t<tr><td>26</td><td>Marvel   </td><td>Hail     </td><td>Female</td><td>Great Britain</td><td>28</td><td>5555</td></tr>\n",
       "\t<tr><td>27</td><td>Angelyn  </td><td>Vong     </td><td>Female</td><td>United States</td><td>29</td><td>6125</td></tr>\n",
       "\t<tr><td>28</td><td>Francesca</td><td>Beaudreau</td><td>Female</td><td>France       </td><td>23</td><td>5412</td></tr>\n",
       "\t<tr><td>29</td><td>Garth    </td><td>Gangi    </td><td>Male  </td><td>United States</td><td>41</td><td>3256</td></tr>\n",
       "\t<tr><td>30</td><td>Carla    </td><td>Trumbull </td><td>Female</td><td>Great Britain</td><td>28</td><td>3264</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 24 √ó 7\n",
       "\\begin{tabular}{lllllll}\n",
       " 0 & First Name & Last Name & Gender & Country & Age & Id\\\\\n",
       " <dbl> & <chr> & <chr> & <chr> & <chr> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t  1 & Dulce     & Abril     & Female & United States & 32 & 1562\\\\\n",
       "\t  3 & Philip    & Gent      & Male   & France        & 36 & 2587\\\\\n",
       "\t  5 & Nereida   & Magwood   & Female & United States & 58 & 2468\\\\\n",
       "\t  6 & Gaston    & Brumm     & Male   & United States & 24 & 2554\\\\\n",
       "\t  8 & Earlean   & Melgar    & Female & United States & 27 & 2456\\\\\n",
       "\t  9 & Vincenza  & Weiland   & Female & United States & 40 & 6548\\\\\n",
       "\t 11 & Arcelia   & Bouska    & Female & Great Britain & 39 & 1258\\\\\n",
       "\t 12 & Franklyn  & Unknow    & Male   & France        & 38 & 2579\\\\\n",
       "\t 13 & Sherron   & Ascencio  & Female & Great Britain & 32 & 3256\\\\\n",
       "\t 15 & Kina      & Hazelton  & Female & Great Britain & 31 & 3259\\\\\n",
       "\t 16 & Shavonne  & Pia       & Female & France        & 24 & 1546\\\\\n",
       "\t 17 & Shavon    & Benito    & Female & France        & 39 & 3579\\\\\n",
       "\t 19 & Loreta    & Curren    & Female & France        & 26 & 9654\\\\\n",
       "\t 20 & Teresa    & Strawn    & Female & France        & 46 & 3569\\\\\n",
       "\t 21 & Belinda   & Partain   & Female & United States & 37 & 2564\\\\\n",
       "\t 22 & Holly     & Eudy      & Female & United States & 52 & 8561\\\\\n",
       "\t 23 & Many      & Cuccia    & Female & Great Britain & 46 & 5489\\\\\n",
       "\t 24 & Libbie    & Dalby     & Female & France        & 42 & 5489\\\\\n",
       "\t 25 & Lester    & Prothro   & Male   & France        & 21 & 6574\\\\\n",
       "\t 26 & Marvel    & Hail      & Female & Great Britain & 28 & 5555\\\\\n",
       "\t 27 & Angelyn   & Vong      & Female & United States & 29 & 6125\\\\\n",
       "\t 28 & Francesca & Beaudreau & Female & France        & 23 & 5412\\\\\n",
       "\t 29 & Garth     & Gangi     & Male   & United States & 41 & 3256\\\\\n",
       "\t 30 & Carla     & Trumbull  & Female & Great Britain & 28 & 3264\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 24 √ó 7\n",
       "\n",
       "| 0 &lt;dbl&gt; | First Name &lt;chr&gt; | Last Name &lt;chr&gt; | Gender &lt;chr&gt; | Country &lt;chr&gt; | Age &lt;dbl&gt; | Id &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "|  1 | Dulce     | Abril     | Female | United States | 32 | 1562 |\n",
       "|  3 | Philip    | Gent      | Male   | France        | 36 | 2587 |\n",
       "|  5 | Nereida   | Magwood   | Female | United States | 58 | 2468 |\n",
       "|  6 | Gaston    | Brumm     | Male   | United States | 24 | 2554 |\n",
       "|  8 | Earlean   | Melgar    | Female | United States | 27 | 2456 |\n",
       "|  9 | Vincenza  | Weiland   | Female | United States | 40 | 6548 |\n",
       "| 11 | Arcelia   | Bouska    | Female | Great Britain | 39 | 1258 |\n",
       "| 12 | Franklyn  | Unknow    | Male   | France        | 38 | 2579 |\n",
       "| 13 | Sherron   | Ascencio  | Female | Great Britain | 32 | 3256 |\n",
       "| 15 | Kina      | Hazelton  | Female | Great Britain | 31 | 3259 |\n",
       "| 16 | Shavonne  | Pia       | Female | France        | 24 | 1546 |\n",
       "| 17 | Shavon    | Benito    | Female | France        | 39 | 3579 |\n",
       "| 19 | Loreta    | Curren    | Female | France        | 26 | 9654 |\n",
       "| 20 | Teresa    | Strawn    | Female | France        | 46 | 3569 |\n",
       "| 21 | Belinda   | Partain   | Female | United States | 37 | 2564 |\n",
       "| 22 | Holly     | Eudy      | Female | United States | 52 | 8561 |\n",
       "| 23 | Many      | Cuccia    | Female | Great Britain | 46 | 5489 |\n",
       "| 24 | Libbie    | Dalby     | Female | France        | 42 | 5489 |\n",
       "| 25 | Lester    | Prothro   | Male   | France        | 21 | 6574 |\n",
       "| 26 | Marvel    | Hail      | Female | Great Britain | 28 | 5555 |\n",
       "| 27 | Angelyn   | Vong      | Female | United States | 29 | 6125 |\n",
       "| 28 | Francesca | Beaudreau | Female | France        | 23 | 5412 |\n",
       "| 29 | Garth     | Gangi     | Male   | United States | 41 | 3256 |\n",
       "| 30 | Carla     | Trumbull  | Female | Great Britain | 28 | 3264 |\n",
       "\n"
      ],
      "text/plain": [
       "   0  First Name Last Name Gender Country       Age Id  \n",
       "1   1 Dulce      Abril     Female United States 32  1562\n",
       "2   3 Philip     Gent      Male   France        36  2587\n",
       "3   5 Nereida    Magwood   Female United States 58  2468\n",
       "4   6 Gaston     Brumm     Male   United States 24  2554\n",
       "5   8 Earlean    Melgar    Female United States 27  2456\n",
       "6   9 Vincenza   Weiland   Female United States 40  6548\n",
       "7  11 Arcelia    Bouska    Female Great Britain 39  1258\n",
       "8  12 Franklyn   Unknow    Male   France        38  2579\n",
       "9  13 Sherron    Ascencio  Female Great Britain 32  3256\n",
       "10 15 Kina       Hazelton  Female Great Britain 31  3259\n",
       "11 16 Shavonne   Pia       Female France        24  1546\n",
       "12 17 Shavon     Benito    Female France        39  3579\n",
       "13 19 Loreta     Curren    Female France        26  9654\n",
       "14 20 Teresa     Strawn    Female France        46  3569\n",
       "15 21 Belinda    Partain   Female United States 37  2564\n",
       "16 22 Holly      Eudy      Female United States 52  8561\n",
       "17 23 Many       Cuccia    Female Great Britain 46  5489\n",
       "18 24 Libbie     Dalby     Female France        42  5489\n",
       "19 25 Lester     Prothro   Male   France        21  6574\n",
       "20 26 Marvel     Hail      Female Great Britain 28  5555\n",
       "21 27 Angelyn    Vong      Female United States 29  6125\n",
       "22 28 Francesca  Beaudreau Female France        23  5412\n",
       "23 29 Garth      Gangi     Male   United States 41  3256\n",
       "24 30 Carla      Trumbull  Female Great Britain 28  3264"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[!is.na(data$Id), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line selects all rows from data where the `id` column is NOT missing. The is.na(data$Id) part creates a logical vector that's `TRUE` for rows where `Id` is missing and `FALSE` otherwise. The ! (not) operator flips these values, so !is.na(data$Age) is `TRUE` for rows with valid values. Using this inside the square brackets tells R to keep only those rows, effectively filtering out rows with missing Age values.\n",
    "\n",
    "3. We can also replace the missing values by using a similar syntaxis: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data$Id[is.na(data$Id)] <- -3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 30 √ó 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>0</th><th scope=col>First Name</th><th scope=col>Last Name</th><th scope=col>Gender</th><th scope=col>Country</th><th scope=col>Age</th><th scope=col>Id</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1</td><td>Dulce    </td><td>Abril    </td><td>Female</td><td>United States</td><td>32</td><td>1562</td></tr>\n",
       "\t<tr><td> 2</td><td>Mara     </td><td>Hashimoto</td><td>Female</td><td>Great Britain</td><td>25</td><td>  -3</td></tr>\n",
       "\t<tr><td> 3</td><td>Philip   </td><td>Gent     </td><td>Male  </td><td>France       </td><td>36</td><td>2587</td></tr>\n",
       "\t<tr><td> 4</td><td>Kathleen </td><td>Hanner   </td><td>Female</td><td>United States</td><td>25</td><td>  -3</td></tr>\n",
       "\t<tr><td> 5</td><td>Nereida  </td><td>Magwood  </td><td>Female</td><td>United States</td><td>58</td><td>2468</td></tr>\n",
       "\t<tr><td> 6</td><td>Gaston   </td><td>Brumm    </td><td>Male  </td><td>United States</td><td>24</td><td>2554</td></tr>\n",
       "\t<tr><td> 7</td><td>Etta     </td><td>Hurn     </td><td>Female</td><td>Great Britain</td><td>56</td><td>  -3</td></tr>\n",
       "\t<tr><td> 8</td><td>Earlean  </td><td>Melgar   </td><td>Female</td><td>United States</td><td>27</td><td>2456</td></tr>\n",
       "\t<tr><td> 9</td><td>Vincenza </td><td>Weiland  </td><td>Female</td><td>United States</td><td>40</td><td>6548</td></tr>\n",
       "\t<tr><td>10</td><td>Fallon   </td><td>Winward  </td><td>Female</td><td>Great Britain</td><td>28</td><td>  -3</td></tr>\n",
       "\t<tr><td>11</td><td>Arcelia  </td><td>Bouska   </td><td>Female</td><td>Great Britain</td><td>39</td><td>1258</td></tr>\n",
       "\t<tr><td>12</td><td>Franklyn </td><td>Unknow   </td><td>Male  </td><td>France       </td><td>38</td><td>2579</td></tr>\n",
       "\t<tr><td>13</td><td>Sherron  </td><td>Ascencio </td><td>Female</td><td>Great Britain</td><td>32</td><td>3256</td></tr>\n",
       "\t<tr><td>14</td><td>Marcel   </td><td>Zabriskie</td><td>Male  </td><td>Great Britain</td><td>26</td><td>  -3</td></tr>\n",
       "\t<tr><td>15</td><td>Kina     </td><td>Hazelton </td><td>Female</td><td>Great Britain</td><td>31</td><td>3259</td></tr>\n",
       "\t<tr><td>16</td><td>Shavonne </td><td>Pia      </td><td>Female</td><td>France       </td><td>24</td><td>1546</td></tr>\n",
       "\t<tr><td>17</td><td>Shavon   </td><td>Benito   </td><td>Female</td><td>France       </td><td>39</td><td>3579</td></tr>\n",
       "\t<tr><td>18</td><td>Lauralee </td><td>Perrine  </td><td>Female</td><td>Great Britain</td><td>28</td><td>  -3</td></tr>\n",
       "\t<tr><td>19</td><td>Loreta   </td><td>Curren   </td><td>Female</td><td>France       </td><td>26</td><td>9654</td></tr>\n",
       "\t<tr><td>20</td><td>Teresa   </td><td>Strawn   </td><td>Female</td><td>France       </td><td>46</td><td>3569</td></tr>\n",
       "\t<tr><td>21</td><td>Belinda  </td><td>Partain  </td><td>Female</td><td>United States</td><td>37</td><td>2564</td></tr>\n",
       "\t<tr><td>22</td><td>Holly    </td><td>Eudy     </td><td>Female</td><td>United States</td><td>52</td><td>8561</td></tr>\n",
       "\t<tr><td>23</td><td>Many     </td><td>Cuccia   </td><td>Female</td><td>Great Britain</td><td>46</td><td>5489</td></tr>\n",
       "\t<tr><td>24</td><td>Libbie   </td><td>Dalby    </td><td>Female</td><td>France       </td><td>42</td><td>5489</td></tr>\n",
       "\t<tr><td>25</td><td>Lester   </td><td>Prothro  </td><td>Male  </td><td>France       </td><td>21</td><td>6574</td></tr>\n",
       "\t<tr><td>26</td><td>Marvel   </td><td>Hail     </td><td>Female</td><td>Great Britain</td><td>28</td><td>5555</td></tr>\n",
       "\t<tr><td>27</td><td>Angelyn  </td><td>Vong     </td><td>Female</td><td>United States</td><td>29</td><td>6125</td></tr>\n",
       "\t<tr><td>28</td><td>Francesca</td><td>Beaudreau</td><td>Female</td><td>France       </td><td>23</td><td>5412</td></tr>\n",
       "\t<tr><td>29</td><td>Garth    </td><td>Gangi    </td><td>Male  </td><td>United States</td><td>41</td><td>3256</td></tr>\n",
       "\t<tr><td>30</td><td>Carla    </td><td>Trumbull </td><td>Female</td><td>Great Britain</td><td>28</td><td>3264</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 30 √ó 7\n",
       "\\begin{tabular}{lllllll}\n",
       " 0 & First Name & Last Name & Gender & Country & Age & Id\\\\\n",
       " <dbl> & <chr> & <chr> & <chr> & <chr> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t  1 & Dulce     & Abril     & Female & United States & 32 & 1562\\\\\n",
       "\t  2 & Mara      & Hashimoto & Female & Great Britain & 25 &   -3\\\\\n",
       "\t  3 & Philip    & Gent      & Male   & France        & 36 & 2587\\\\\n",
       "\t  4 & Kathleen  & Hanner    & Female & United States & 25 &   -3\\\\\n",
       "\t  5 & Nereida   & Magwood   & Female & United States & 58 & 2468\\\\\n",
       "\t  6 & Gaston    & Brumm     & Male   & United States & 24 & 2554\\\\\n",
       "\t  7 & Etta      & Hurn      & Female & Great Britain & 56 &   -3\\\\\n",
       "\t  8 & Earlean   & Melgar    & Female & United States & 27 & 2456\\\\\n",
       "\t  9 & Vincenza  & Weiland   & Female & United States & 40 & 6548\\\\\n",
       "\t 10 & Fallon    & Winward   & Female & Great Britain & 28 &   -3\\\\\n",
       "\t 11 & Arcelia   & Bouska    & Female & Great Britain & 39 & 1258\\\\\n",
       "\t 12 & Franklyn  & Unknow    & Male   & France        & 38 & 2579\\\\\n",
       "\t 13 & Sherron   & Ascencio  & Female & Great Britain & 32 & 3256\\\\\n",
       "\t 14 & Marcel    & Zabriskie & Male   & Great Britain & 26 &   -3\\\\\n",
       "\t 15 & Kina      & Hazelton  & Female & Great Britain & 31 & 3259\\\\\n",
       "\t 16 & Shavonne  & Pia       & Female & France        & 24 & 1546\\\\\n",
       "\t 17 & Shavon    & Benito    & Female & France        & 39 & 3579\\\\\n",
       "\t 18 & Lauralee  & Perrine   & Female & Great Britain & 28 &   -3\\\\\n",
       "\t 19 & Loreta    & Curren    & Female & France        & 26 & 9654\\\\\n",
       "\t 20 & Teresa    & Strawn    & Female & France        & 46 & 3569\\\\\n",
       "\t 21 & Belinda   & Partain   & Female & United States & 37 & 2564\\\\\n",
       "\t 22 & Holly     & Eudy      & Female & United States & 52 & 8561\\\\\n",
       "\t 23 & Many      & Cuccia    & Female & Great Britain & 46 & 5489\\\\\n",
       "\t 24 & Libbie    & Dalby     & Female & France        & 42 & 5489\\\\\n",
       "\t 25 & Lester    & Prothro   & Male   & France        & 21 & 6574\\\\\n",
       "\t 26 & Marvel    & Hail      & Female & Great Britain & 28 & 5555\\\\\n",
       "\t 27 & Angelyn   & Vong      & Female & United States & 29 & 6125\\\\\n",
       "\t 28 & Francesca & Beaudreau & Female & France        & 23 & 5412\\\\\n",
       "\t 29 & Garth     & Gangi     & Male   & United States & 41 & 3256\\\\\n",
       "\t 30 & Carla     & Trumbull  & Female & Great Britain & 28 & 3264\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 30 √ó 7\n",
       "\n",
       "| 0 &lt;dbl&gt; | First Name &lt;chr&gt; | Last Name &lt;chr&gt; | Gender &lt;chr&gt; | Country &lt;chr&gt; | Age &lt;dbl&gt; | Id &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "|  1 | Dulce     | Abril     | Female | United States | 32 | 1562 |\n",
       "|  2 | Mara      | Hashimoto | Female | Great Britain | 25 |   -3 |\n",
       "|  3 | Philip    | Gent      | Male   | France        | 36 | 2587 |\n",
       "|  4 | Kathleen  | Hanner    | Female | United States | 25 |   -3 |\n",
       "|  5 | Nereida   | Magwood   | Female | United States | 58 | 2468 |\n",
       "|  6 | Gaston    | Brumm     | Male   | United States | 24 | 2554 |\n",
       "|  7 | Etta      | Hurn      | Female | Great Britain | 56 |   -3 |\n",
       "|  8 | Earlean   | Melgar    | Female | United States | 27 | 2456 |\n",
       "|  9 | Vincenza  | Weiland   | Female | United States | 40 | 6548 |\n",
       "| 10 | Fallon    | Winward   | Female | Great Britain | 28 |   -3 |\n",
       "| 11 | Arcelia   | Bouska    | Female | Great Britain | 39 | 1258 |\n",
       "| 12 | Franklyn  | Unknow    | Male   | France        | 38 | 2579 |\n",
       "| 13 | Sherron   | Ascencio  | Female | Great Britain | 32 | 3256 |\n",
       "| 14 | Marcel    | Zabriskie | Male   | Great Britain | 26 |   -3 |\n",
       "| 15 | Kina      | Hazelton  | Female | Great Britain | 31 | 3259 |\n",
       "| 16 | Shavonne  | Pia       | Female | France        | 24 | 1546 |\n",
       "| 17 | Shavon    | Benito    | Female | France        | 39 | 3579 |\n",
       "| 18 | Lauralee  | Perrine   | Female | Great Britain | 28 |   -3 |\n",
       "| 19 | Loreta    | Curren    | Female | France        | 26 | 9654 |\n",
       "| 20 | Teresa    | Strawn    | Female | France        | 46 | 3569 |\n",
       "| 21 | Belinda   | Partain   | Female | United States | 37 | 2564 |\n",
       "| 22 | Holly     | Eudy      | Female | United States | 52 | 8561 |\n",
       "| 23 | Many      | Cuccia    | Female | Great Britain | 46 | 5489 |\n",
       "| 24 | Libbie    | Dalby     | Female | France        | 42 | 5489 |\n",
       "| 25 | Lester    | Prothro   | Male   | France        | 21 | 6574 |\n",
       "| 26 | Marvel    | Hail      | Female | Great Britain | 28 | 5555 |\n",
       "| 27 | Angelyn   | Vong      | Female | United States | 29 | 6125 |\n",
       "| 28 | Francesca | Beaudreau | Female | France        | 23 | 5412 |\n",
       "| 29 | Garth     | Gangi     | Male   | United States | 41 | 3256 |\n",
       "| 30 | Carla     | Trumbull  | Female | Great Britain | 28 | 3264 |\n",
       "\n"
      ],
      "text/plain": [
       "   0  First Name Last Name Gender Country       Age Id  \n",
       "1   1 Dulce      Abril     Female United States 32  1562\n",
       "2   2 Mara       Hashimoto Female Great Britain 25    -3\n",
       "3   3 Philip     Gent      Male   France        36  2587\n",
       "4   4 Kathleen   Hanner    Female United States 25    -3\n",
       "5   5 Nereida    Magwood   Female United States 58  2468\n",
       "6   6 Gaston     Brumm     Male   United States 24  2554\n",
       "7   7 Etta       Hurn      Female Great Britain 56    -3\n",
       "8   8 Earlean    Melgar    Female United States 27  2456\n",
       "9   9 Vincenza   Weiland   Female United States 40  6548\n",
       "10 10 Fallon     Winward   Female Great Britain 28    -3\n",
       "11 11 Arcelia    Bouska    Female Great Britain 39  1258\n",
       "12 12 Franklyn   Unknow    Male   France        38  2579\n",
       "13 13 Sherron    Ascencio  Female Great Britain 32  3256\n",
       "14 14 Marcel     Zabriskie Male   Great Britain 26    -3\n",
       "15 15 Kina       Hazelton  Female Great Britain 31  3259\n",
       "16 16 Shavonne   Pia       Female France        24  1546\n",
       "17 17 Shavon     Benito    Female France        39  3579\n",
       "18 18 Lauralee   Perrine   Female Great Britain 28    -3\n",
       "19 19 Loreta     Curren    Female France        26  9654\n",
       "20 20 Teresa     Strawn    Female France        46  3569\n",
       "21 21 Belinda    Partain   Female United States 37  2564\n",
       "22 22 Holly      Eudy      Female United States 52  8561\n",
       "23 23 Many       Cuccia    Female Great Britain 46  5489\n",
       "24 24 Libbie     Dalby     Female France        42  5489\n",
       "25 25 Lester     Prothro   Male   France        21  6574\n",
       "26 26 Marvel     Hail      Female Great Britain 28  5555\n",
       "27 27 Angelyn    Vong      Female United States 29  6125\n",
       "28 28 Francesca  Beaudreau Female France        23  5412\n",
       "29 29 Garth      Gangi     Male   United States 41  3256\n",
       "30 30 Carla      Trumbull  Female Great Britain 28  3264"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "The difference between these two operations is important:\n",
    "\n",
    "- `data[!is.na(data$Id), ]`  \n",
    "  This **filters the data frame** to keep only the rows where the `Id` column is **not missing**. The resulting data frame excludes all rows with `NA` in `Id`, but the original data remains unchanged unless you assign the result back to `data` (unless we overwrite it)\n",
    "\n",
    "- `data$Id[is.na(data$Id)] <- -3`  \n",
    "  This **directly modifies the `Id` column** in the existing data frame by replacing all missing values (`NA`) with `-3`. This overwrites the data in-place, so the missing values are permanently replaced and can‚Äôt be recovered unless you reload the original data.\n",
    "\n",
    "The first operation **filters out missing data**, while the second **replaces missing values** with a specified number.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. If we have multiple columns with missing data, we can remove all columns with any missing data as: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 30 √ó 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>0</th><th scope=col>First Name</th><th scope=col>Last Name</th><th scope=col>Gender</th><th scope=col>Country</th><th scope=col>Age</th><th scope=col>Id</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1</td><td>Dulce    </td><td>Abril    </td><td>Female</td><td>United States</td><td>32</td><td>1562</td></tr>\n",
       "\t<tr><td> 2</td><td>Mara     </td><td>Hashimoto</td><td>Female</td><td>Great Britain</td><td>25</td><td>  -3</td></tr>\n",
       "\t<tr><td> 3</td><td>Philip   </td><td>Gent     </td><td>Male  </td><td>France       </td><td>36</td><td>2587</td></tr>\n",
       "\t<tr><td> 4</td><td>Kathleen </td><td>Hanner   </td><td>Female</td><td>United States</td><td>25</td><td>  -3</td></tr>\n",
       "\t<tr><td> 5</td><td>Nereida  </td><td>Magwood  </td><td>Female</td><td>United States</td><td>58</td><td>2468</td></tr>\n",
       "\t<tr><td> 6</td><td>Gaston   </td><td>Brumm    </td><td>Male  </td><td>United States</td><td>24</td><td>2554</td></tr>\n",
       "\t<tr><td> 7</td><td>Etta     </td><td>Hurn     </td><td>Female</td><td>Great Britain</td><td>56</td><td>  -3</td></tr>\n",
       "\t<tr><td> 8</td><td>Earlean  </td><td>Melgar   </td><td>Female</td><td>United States</td><td>27</td><td>2456</td></tr>\n",
       "\t<tr><td> 9</td><td>Vincenza </td><td>Weiland  </td><td>Female</td><td>United States</td><td>40</td><td>6548</td></tr>\n",
       "\t<tr><td>10</td><td>Fallon   </td><td>Winward  </td><td>Female</td><td>Great Britain</td><td>28</td><td>  -3</td></tr>\n",
       "\t<tr><td>11</td><td>Arcelia  </td><td>Bouska   </td><td>Female</td><td>Great Britain</td><td>39</td><td>1258</td></tr>\n",
       "\t<tr><td>12</td><td>Franklyn </td><td>Unknow   </td><td>Male  </td><td>France       </td><td>38</td><td>2579</td></tr>\n",
       "\t<tr><td>13</td><td>Sherron  </td><td>Ascencio </td><td>Female</td><td>Great Britain</td><td>32</td><td>3256</td></tr>\n",
       "\t<tr><td>14</td><td>Marcel   </td><td>Zabriskie</td><td>Male  </td><td>Great Britain</td><td>26</td><td>  -3</td></tr>\n",
       "\t<tr><td>15</td><td>Kina     </td><td>Hazelton </td><td>Female</td><td>Great Britain</td><td>31</td><td>3259</td></tr>\n",
       "\t<tr><td>16</td><td>Shavonne </td><td>Pia      </td><td>Female</td><td>France       </td><td>24</td><td>1546</td></tr>\n",
       "\t<tr><td>17</td><td>Shavon   </td><td>Benito   </td><td>Female</td><td>France       </td><td>39</td><td>3579</td></tr>\n",
       "\t<tr><td>18</td><td>Lauralee </td><td>Perrine  </td><td>Female</td><td>Great Britain</td><td>28</td><td>  -3</td></tr>\n",
       "\t<tr><td>19</td><td>Loreta   </td><td>Curren   </td><td>Female</td><td>France       </td><td>26</td><td>9654</td></tr>\n",
       "\t<tr><td>20</td><td>Teresa   </td><td>Strawn   </td><td>Female</td><td>France       </td><td>46</td><td>3569</td></tr>\n",
       "\t<tr><td>21</td><td>Belinda  </td><td>Partain  </td><td>Female</td><td>United States</td><td>37</td><td>2564</td></tr>\n",
       "\t<tr><td>22</td><td>Holly    </td><td>Eudy     </td><td>Female</td><td>United States</td><td>52</td><td>8561</td></tr>\n",
       "\t<tr><td>23</td><td>Many     </td><td>Cuccia   </td><td>Female</td><td>Great Britain</td><td>46</td><td>5489</td></tr>\n",
       "\t<tr><td>24</td><td>Libbie   </td><td>Dalby    </td><td>Female</td><td>France       </td><td>42</td><td>5489</td></tr>\n",
       "\t<tr><td>25</td><td>Lester   </td><td>Prothro  </td><td>Male  </td><td>France       </td><td>21</td><td>6574</td></tr>\n",
       "\t<tr><td>26</td><td>Marvel   </td><td>Hail     </td><td>Female</td><td>Great Britain</td><td>28</td><td>5555</td></tr>\n",
       "\t<tr><td>27</td><td>Angelyn  </td><td>Vong     </td><td>Female</td><td>United States</td><td>29</td><td>6125</td></tr>\n",
       "\t<tr><td>28</td><td>Francesca</td><td>Beaudreau</td><td>Female</td><td>France       </td><td>23</td><td>5412</td></tr>\n",
       "\t<tr><td>29</td><td>Garth    </td><td>Gangi    </td><td>Male  </td><td>United States</td><td>41</td><td>3256</td></tr>\n",
       "\t<tr><td>30</td><td>Carla    </td><td>Trumbull </td><td>Female</td><td>Great Britain</td><td>28</td><td>3264</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 30 √ó 7\n",
       "\\begin{tabular}{lllllll}\n",
       " 0 & First Name & Last Name & Gender & Country & Age & Id\\\\\n",
       " <dbl> & <chr> & <chr> & <chr> & <chr> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t  1 & Dulce     & Abril     & Female & United States & 32 & 1562\\\\\n",
       "\t  2 & Mara      & Hashimoto & Female & Great Britain & 25 &   -3\\\\\n",
       "\t  3 & Philip    & Gent      & Male   & France        & 36 & 2587\\\\\n",
       "\t  4 & Kathleen  & Hanner    & Female & United States & 25 &   -3\\\\\n",
       "\t  5 & Nereida   & Magwood   & Female & United States & 58 & 2468\\\\\n",
       "\t  6 & Gaston    & Brumm     & Male   & United States & 24 & 2554\\\\\n",
       "\t  7 & Etta      & Hurn      & Female & Great Britain & 56 &   -3\\\\\n",
       "\t  8 & Earlean   & Melgar    & Female & United States & 27 & 2456\\\\\n",
       "\t  9 & Vincenza  & Weiland   & Female & United States & 40 & 6548\\\\\n",
       "\t 10 & Fallon    & Winward   & Female & Great Britain & 28 &   -3\\\\\n",
       "\t 11 & Arcelia   & Bouska    & Female & Great Britain & 39 & 1258\\\\\n",
       "\t 12 & Franklyn  & Unknow    & Male   & France        & 38 & 2579\\\\\n",
       "\t 13 & Sherron   & Ascencio  & Female & Great Britain & 32 & 3256\\\\\n",
       "\t 14 & Marcel    & Zabriskie & Male   & Great Britain & 26 &   -3\\\\\n",
       "\t 15 & Kina      & Hazelton  & Female & Great Britain & 31 & 3259\\\\\n",
       "\t 16 & Shavonne  & Pia       & Female & France        & 24 & 1546\\\\\n",
       "\t 17 & Shavon    & Benito    & Female & France        & 39 & 3579\\\\\n",
       "\t 18 & Lauralee  & Perrine   & Female & Great Britain & 28 &   -3\\\\\n",
       "\t 19 & Loreta    & Curren    & Female & France        & 26 & 9654\\\\\n",
       "\t 20 & Teresa    & Strawn    & Female & France        & 46 & 3569\\\\\n",
       "\t 21 & Belinda   & Partain   & Female & United States & 37 & 2564\\\\\n",
       "\t 22 & Holly     & Eudy      & Female & United States & 52 & 8561\\\\\n",
       "\t 23 & Many      & Cuccia    & Female & Great Britain & 46 & 5489\\\\\n",
       "\t 24 & Libbie    & Dalby     & Female & France        & 42 & 5489\\\\\n",
       "\t 25 & Lester    & Prothro   & Male   & France        & 21 & 6574\\\\\n",
       "\t 26 & Marvel    & Hail      & Female & Great Britain & 28 & 5555\\\\\n",
       "\t 27 & Angelyn   & Vong      & Female & United States & 29 & 6125\\\\\n",
       "\t 28 & Francesca & Beaudreau & Female & France        & 23 & 5412\\\\\n",
       "\t 29 & Garth     & Gangi     & Male   & United States & 41 & 3256\\\\\n",
       "\t 30 & Carla     & Trumbull  & Female & Great Britain & 28 & 3264\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 30 √ó 7\n",
       "\n",
       "| 0 &lt;dbl&gt; | First Name &lt;chr&gt; | Last Name &lt;chr&gt; | Gender &lt;chr&gt; | Country &lt;chr&gt; | Age &lt;dbl&gt; | Id &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "|  1 | Dulce     | Abril     | Female | United States | 32 | 1562 |\n",
       "|  2 | Mara      | Hashimoto | Female | Great Britain | 25 |   -3 |\n",
       "|  3 | Philip    | Gent      | Male   | France        | 36 | 2587 |\n",
       "|  4 | Kathleen  | Hanner    | Female | United States | 25 |   -3 |\n",
       "|  5 | Nereida   | Magwood   | Female | United States | 58 | 2468 |\n",
       "|  6 | Gaston    | Brumm     | Male   | United States | 24 | 2554 |\n",
       "|  7 | Etta      | Hurn      | Female | Great Britain | 56 |   -3 |\n",
       "|  8 | Earlean   | Melgar    | Female | United States | 27 | 2456 |\n",
       "|  9 | Vincenza  | Weiland   | Female | United States | 40 | 6548 |\n",
       "| 10 | Fallon    | Winward   | Female | Great Britain | 28 |   -3 |\n",
       "| 11 | Arcelia   | Bouska    | Female | Great Britain | 39 | 1258 |\n",
       "| 12 | Franklyn  | Unknow    | Male   | France        | 38 | 2579 |\n",
       "| 13 | Sherron   | Ascencio  | Female | Great Britain | 32 | 3256 |\n",
       "| 14 | Marcel    | Zabriskie | Male   | Great Britain | 26 |   -3 |\n",
       "| 15 | Kina      | Hazelton  | Female | Great Britain | 31 | 3259 |\n",
       "| 16 | Shavonne  | Pia       | Female | France        | 24 | 1546 |\n",
       "| 17 | Shavon    | Benito    | Female | France        | 39 | 3579 |\n",
       "| 18 | Lauralee  | Perrine   | Female | Great Britain | 28 |   -3 |\n",
       "| 19 | Loreta    | Curren    | Female | France        | 26 | 9654 |\n",
       "| 20 | Teresa    | Strawn    | Female | France        | 46 | 3569 |\n",
       "| 21 | Belinda   | Partain   | Female | United States | 37 | 2564 |\n",
       "| 22 | Holly     | Eudy      | Female | United States | 52 | 8561 |\n",
       "| 23 | Many      | Cuccia    | Female | Great Britain | 46 | 5489 |\n",
       "| 24 | Libbie    | Dalby     | Female | France        | 42 | 5489 |\n",
       "| 25 | Lester    | Prothro   | Male   | France        | 21 | 6574 |\n",
       "| 26 | Marvel    | Hail      | Female | Great Britain | 28 | 5555 |\n",
       "| 27 | Angelyn   | Vong      | Female | United States | 29 | 6125 |\n",
       "| 28 | Francesca | Beaudreau | Female | France        | 23 | 5412 |\n",
       "| 29 | Garth     | Gangi     | Male   | United States | 41 | 3256 |\n",
       "| 30 | Carla     | Trumbull  | Female | Great Britain | 28 | 3264 |\n",
       "\n"
      ],
      "text/plain": [
       "   0  First Name Last Name Gender Country       Age Id  \n",
       "1   1 Dulce      Abril     Female United States 32  1562\n",
       "2   2 Mara       Hashimoto Female Great Britain 25    -3\n",
       "3   3 Philip     Gent      Male   France        36  2587\n",
       "4   4 Kathleen   Hanner    Female United States 25    -3\n",
       "5   5 Nereida    Magwood   Female United States 58  2468\n",
       "6   6 Gaston     Brumm     Male   United States 24  2554\n",
       "7   7 Etta       Hurn      Female Great Britain 56    -3\n",
       "8   8 Earlean    Melgar    Female United States 27  2456\n",
       "9   9 Vincenza   Weiland   Female United States 40  6548\n",
       "10 10 Fallon     Winward   Female Great Britain 28    -3\n",
       "11 11 Arcelia    Bouska    Female Great Britain 39  1258\n",
       "12 12 Franklyn   Unknow    Male   France        38  2579\n",
       "13 13 Sherron    Ascencio  Female Great Britain 32  3256\n",
       "14 14 Marcel     Zabriskie Male   Great Britain 26    -3\n",
       "15 15 Kina       Hazelton  Female Great Britain 31  3259\n",
       "16 16 Shavonne   Pia       Female France        24  1546\n",
       "17 17 Shavon     Benito    Female France        39  3579\n",
       "18 18 Lauralee   Perrine   Female Great Britain 28    -3\n",
       "19 19 Loreta     Curren    Female France        26  9654\n",
       "20 20 Teresa     Strawn    Female France        46  3569\n",
       "21 21 Belinda    Partain   Female United States 37  2564\n",
       "22 22 Holly      Eudy      Female United States 52  8561\n",
       "23 23 Many       Cuccia    Female Great Britain 46  5489\n",
       "24 24 Libbie     Dalby     Female France        42  5489\n",
       "25 25 Lester     Prothro   Male   France        21  6574\n",
       "26 26 Marvel     Hail      Female Great Britain 28  5555\n",
       "27 27 Angelyn    Vong      Female United States 29  6125\n",
       "28 28 Francesca  Beaudreau Female France        23  5412\n",
       "29 29 Garth      Gangi     Male   United States 41  3256\n",
       "30 30 Carla      Trumbull  Female Great Britain 28  3264"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[, colSums(is.na(data)) == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line selects all columns from the `data` data frame that have **no missing values**. As before,`is.na(data)` creates a logical matrix indicating missing values (`TRUE` if missing) and `colSums(is.na(data))` counts how many missing values are in each column.\n",
    "The comma in `data[, ...]` indicates that we are selecting **columns** (after the comma) and keeping **all rows** (before the comma, which is empty). Subsetting with `data[, colSums(is.na(data)) == 0]` therefore keeps only those columns that have no missing values, while retaining all rows.\n",
    "\n",
    "*Keep in mind that nothing changed in this example because we overwrote all `NA`values!!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `session_1` folder, you will find the example dataset `session_1_practice_airquality.csv`. This dataset was sourced from the [UCI Air Quality dataset](https://archive.ics.uci.edu/dataset/360/air+quality). Take a moment to read about the dataset on the website to understand what kind of data it contains. Then:\n",
    "1. Try to search on Google how to load csv files in R. (No chatgpt)\n",
    "2. After loading the data, inspect the first few rows. \n",
    "3. Identify missing values.\n",
    "4. Describe all columns the data by (1) removing missing values and (2) replace missing values by the column mean (inspect online the function `mean()`)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
